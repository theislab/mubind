{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9b91376-6d9c-4b0a-9302-88600cca8fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c78083b8-3d92-4531-8434-51ee2c20cfc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fontconfig warning: ignoring UTF-8: not a valid region tag\n",
      "/Users/egeerdogan/mambaforge/envs/mubind/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import mubind as mb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import bindome as bd\n",
    "bd.constants.ANNOTATIONS_DIRECTORY = 'annotations'\n",
    "# mb.models.Mubind\n",
    "import torch.optim as topti\n",
    "import torch.utils.data as tdata\n",
    "import matplotlib.pyplot as plt\n",
    "import logomaker\n",
    "import os\n",
    "import scipy\n",
    "import pickle\n",
    "\n",
    "# Use a GPU if available, as it should be faster.\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device: \" + str(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21f8e7e-37d2-45bb-be02-75868ec61652",
   "metadata": {},
   "source": [
    "# SELEX (one dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c3f5428-a57e-430b-987d-c8172d789d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rounds = 1\n",
    "data = pd.read_csv('../data/countTable.0.CTCF_r3.tsv.gz', sep='\\t', header=None)\n",
    "data.columns = ['seq'] + [i for i in range(n_rounds+1)]\n",
    "data.index = data['seq']\n",
    "del data['seq']\n",
    "data = data.sample(n=1000)\n",
    "labels = list(data.columns[:n_rounds + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "410aae35-b5c0-463c-8a2e-69058fa9283c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = mb.datasets.SelexDataset(data, n_rounds=n_rounds, labels=labels)\n",
    "train = tdata.DataLoader(dataset=dataset, batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2c08380-4a30-4552-aab3-a927038d99a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next w 15 <class 'int'>\n",
      "# rounds [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1]\n",
      "# batches 1\n",
      "# kernels 4\n",
      "# initial w 15\n",
      "# enr_series True\n",
      "{'kernels': [0, 15, 15, 15], 'n_rounds': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'init_random': False, 'n_batches': 1, 'enr_series': True, 'n_kernels': 4}\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1]\n",
      "\n",
      "Kernel to optimize 0\n",
      "\n",
      "FREEZING KERNELS\n",
      "setting grad status of kernel at 0 to 1\n",
      "setting grad status of kernel at 1 to 0\n",
      "setting grad status of kernel at 2 to 0\n",
      "setting grad status of kernel at 3 to 0\n",
      "\n",
      "\n",
      "kernels mask None\n",
      "optimizing using <class 'torch.optim.adam.Adam'> and <class 'mubind.tl.loss.PoissonLoss'> n_epochs 6 early_stopping 50\n",
      "lr= 0.01, weight_decay= 0.001, dir weight= 0\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "The shape of the mask [256, 1] at index 1 does not match the shape of the indexed tensor [256, 2] at index 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model, best_loss \u001b[39m=\u001b[39m mb\u001b[39m.\u001b[39;49mtl\u001b[39m.\u001b[39;49moptimize_iterative(train, device, num_epochs\u001b[39m=\u001b[39;49m\u001b[39m6\u001b[39;49m, show_logo\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, \n\u001b[1;32m      2\u001b[0m                                          early_stopping\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m, log_each\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n",
      "File \u001b[0;32m~/Desktop/theislab/mubind/mubind/tl/prediction.py:410\u001b[0m, in \u001b[0;36moptimize_iterative\u001b[0;34m(train, device, n_kernels, w, max_w, num_epochs, early_stopping, log_each, opt_kernel_shift, opt_kernel_length, expand_length_max, expand_length_step, show_logo, optimiser, criterion, seed, init_random, joint_learning, ignore_kernel, lr, weight_decay, stop_at_kernel, dirichlet_regularization, verbose, exp_max, shift_max, shift_step, r2_per_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mkernels mask\u001b[39m\u001b[39m\"\u001b[39m, model\u001b[39m.\u001b[39mget_ignore_kernel())\n\u001b[1;32m    409\u001b[0m \u001b[39m# assert False\u001b[39;00m\n\u001b[0;32m--> 410\u001b[0m optimize_simple(\n\u001b[1;32m    411\u001b[0m     model,\n\u001b[1;32m    412\u001b[0m     train,\n\u001b[1;32m    413\u001b[0m     device,\n\u001b[1;32m    414\u001b[0m     next_optimiser,\n\u001b[1;32m    415\u001b[0m     criterion,\n\u001b[1;32m    416\u001b[0m     num_epochs\u001b[39m=\u001b[39;49mnum_epochs,\n\u001b[1;32m    417\u001b[0m     early_stopping\u001b[39m=\u001b[39;49mnext_early_stopping,\n\u001b[1;32m    418\u001b[0m     log_each\u001b[39m=\u001b[39;49mlog_each,\n\u001b[1;32m    419\u001b[0m     dirichlet_regularization\u001b[39m=\u001b[39;49mdirichlet_regularization,\n\u001b[1;32m    420\u001b[0m     exp_max\u001b[39m=\u001b[39;49mexp_max,\n\u001b[1;32m    421\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    422\u001b[0m )\n\u001b[1;32m    424\u001b[0m model\u001b[39m.\u001b[39mloss_color \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(np\u001b[39m.\u001b[39mrepeat(colors[i], \u001b[39mlen\u001b[39m(model\u001b[39m.\u001b[39mloss_history) \u001b[39m-\u001b[39m \u001b[39mlen\u001b[39m(model\u001b[39m.\u001b[39mloss_color)))\n\u001b[1;32m    425\u001b[0m \u001b[39m# probably here load the state of the best epoch and save\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/theislab/mubind/mubind/tl/prediction.py:178\u001b[0m, in \u001b[0;36moptimize_simple\u001b[0;34m(model, train_dataloader, device, optimiser, criterion, num_epochs, early_stopping, dirichlet_regularization, exp_max, log_each, verbose, r2_per_epoch)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(mask\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]):\n\u001b[1;32m    176\u001b[0m     mask[:, i] \u001b[39m=\u001b[39m \u001b[39m~\u001b[39m(n_rounds \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m \u001b[39m<\u001b[39m i)\n\u001b[0;32m--> 178\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs[mask], rounds[mask]) \u001b[39m+\u001b[39m dir_weight\n\u001b[1;32m    180\u001b[0m \u001b[39m# loss = criterion(outputs, rounds) + 0.01*reconstruction_crit(reconstruction, residues) + dir_weight\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \u001b[39mif\u001b[39;00m exp_max \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[0;31mIndexError\u001b[0m: The shape of the mask [256, 1] at index 1 does not match the shape of the indexed tensor [256, 2] at index 1"
     ]
    }
   ],
   "source": [
    "model, best_loss = mb.tl.optimize_iterative(train, device, num_epochs=6, show_logo=False, \n",
    "                                         early_stopping=50, log_each=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c740e74e-cf52-40cb-b83a-d6ef27aac52b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: [0.00032254469330794677]\n"
     ]
    }
   ],
   "source": [
    "r2 = mb.pl.R2_calculation(model, train)\n",
    "print(\"R^2:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f950af71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kernels': [0, 1], 'n_rounds': 1, 'init_random': True, 'n_batches': 64, 'enr_series': False, 'n_kernels': 2}\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "model = mb.models.Mubind(\n",
    "    datatype=\"selex\",\n",
    "    kernels=[0, 1],\n",
    "    n_rounds=n_rounds,\n",
    "    init_random=True,\n",
    "    n_batches=64,\n",
    "    enr_series=False,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab20b0b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simple\n",
      "here...  2\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 16 elements, new values have 4 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [18], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m mode \u001b[39min\u001b[39;00m [\u001b[39m'\u001b[39m\u001b[39msimple\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcomplex\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtriangle\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[1;32m      2\u001b[0m     \u001b[39mprint\u001b[39m(mode)\n\u001b[0;32m----> 3\u001b[0m     mb\u001b[39m.\u001b[39;49mpl\u001b[39m.\u001b[39;49mconv_di(model, mode\u001b[39m=\u001b[39;49mmode, figsize\u001b[39m=\u001b[39;49m(\u001b[39m5\u001b[39;49m, \u001b[39m3\u001b[39;49m))\n",
      "File \u001b[0;32m~/Desktop/theislab/mubind/mubind/pl/plotting.py:95\u001b[0m, in \u001b[0;36mconv_di\u001b[0;34m(model, figsize, mode)\u001b[0m\n\u001b[1;32m     76\u001b[0m weights \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(weights)\n\u001b[1;32m     77\u001b[0m weights\u001b[39m.\u001b[39mindex \u001b[39m=\u001b[39m (\n\u001b[1;32m     78\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mAA\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     79\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mAC\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mTT\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     94\u001b[0m )\n\u001b[0;32m---> 95\u001b[0m weights\u001b[39m.\u001b[39;49mindex \u001b[39m=\u001b[39m (\u001b[39m'\u001b[39m\u001b[39mA\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mC\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mG\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mT\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     97\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mcomplex\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m     98\u001b[0m     df \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/mambaforge/envs/mubind/lib/python3.10/site-packages/pandas/core/generic.py:5915\u001b[0m, in \u001b[0;36mNDFrame.__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   5913\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   5914\u001b[0m     \u001b[39mobject\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__getattribute__\u001b[39m(\u001b[39mself\u001b[39m, name)\n\u001b[0;32m-> 5915\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mobject\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__setattr__\u001b[39;49m(\u001b[39mself\u001b[39;49m, name, value)\n\u001b[1;32m   5916\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m:\n\u001b[1;32m   5917\u001b[0m     \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/mubind/lib/python3.10/site-packages/pandas/_libs/properties.pyx:69\u001b[0m, in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/mambaforge/envs/mubind/lib/python3.10/site-packages/pandas/core/generic.py:823\u001b[0m, in \u001b[0;36mNDFrame._set_axis\u001b[0;34m(self, axis, labels)\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_set_axis\u001b[39m(\u001b[39mself\u001b[39m, axis: \u001b[39mint\u001b[39m, labels: AnyArrayLike \u001b[39m|\u001b[39m \u001b[39mlist\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    822\u001b[0m     labels \u001b[39m=\u001b[39m ensure_index(labels)\n\u001b[0;32m--> 823\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mset_axis(axis, labels)\n\u001b[1;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_clear_item_cache()\n",
      "File \u001b[0;32m~/mambaforge/envs/mubind/lib/python3.10/site-packages/pandas/core/internals/managers.py:227\u001b[0m, in \u001b[0;36mBaseBlockManager.set_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mset_axis\u001b[39m(\u001b[39mself\u001b[39m, axis: \u001b[39mint\u001b[39m, new_labels: Index) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    226\u001b[0m     \u001b[39m# Caller is responsible for ensuring we have an Index object.\u001b[39;00m\n\u001b[0;32m--> 227\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_set_axis(axis, new_labels)\n\u001b[1;32m    228\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes[axis] \u001b[39m=\u001b[39m new_labels\n",
      "File \u001b[0;32m~/mambaforge/envs/mubind/lib/python3.10/site-packages/pandas/core/internals/base.py:70\u001b[0m, in \u001b[0;36mDataManager._validate_set_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[39melif\u001b[39;00m new_len \u001b[39m!=\u001b[39m old_len:\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     71\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLength mismatch: Expected axis has \u001b[39m\u001b[39m{\u001b[39;00mold_len\u001b[39m}\u001b[39;00m\u001b[39m elements, new \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     72\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mvalues have \u001b[39m\u001b[39m{\u001b[39;00mnew_len\u001b[39m}\u001b[39;00m\u001b[39m elements\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     73\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Length mismatch: Expected axis has 16 elements, new values have 4 elements"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for mode in ['simple', 'complex', 'triangle']:\n",
    "    print(mode)\n",
    "    mb.pl.conv_di(model, mode=mode, figsize=(5, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7c111c-7e53-4488-a02b-a265e8729533",
   "metadata": {
    "tags": []
   },
   "source": [
    "# PBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "349cc672-2c4c-413f-b7ca-226e5708a299",
   "metadata": {},
   "outputs": [],
   "source": [
    "matlab_path = os.path.join(bd.constants.ANNOTATIONS_DIRECTORY, 'pbm', 'affreg', 'PbmDataHom6_norm.mat')\n",
    "mat = scipy.io.loadmat(matlab_path)\n",
    "data = mat['PbmData'][0]\n",
    "seqs_dna =  data[0][5]\n",
    "seqs_dna = [s[0][0] for s in seqs_dna]\n",
    "# load the MSA sequences, one hot encoded\n",
    "df, signal = bd.datasets.PBM.pbm_homeo_affreg()\n",
    "# x, y = pickle.load(open('../../data/example_homeo_PbmData.pkl', 'rb'))\n",
    "# x, y = pickle.load(open('annotations/pbm/example_homeo_PbmData.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49dc5ecc-344d-41a2-8db9-0d1d6b171d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a small subsample\n",
    "# x = x[1:6]\n",
    "seqs_dna = seqs_dna[0:1000]\n",
    "signal = signal[0:1, 0:1000]\n",
    "\n",
    "# shift signal by adding a constant s.t. no negative values are included\n",
    "signal -= np.min(signal)\n",
    "\n",
    "# Set up the dataset\n",
    "df = pd.DataFrame(signal.T)\n",
    "df['seq'] = seqs_dna\n",
    "df.index = df['seq']\n",
    "del df['seq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2df2296a-20ea-42ca-964c-8874bb77a954",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = mb.datasets.PBMDataset(df)\n",
    "train = tdata.DataLoader(dataset=dataset, batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "feaba1b3-f5b1-4e76-af1f-38e94ff0175d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next w 15 <class 'int'>\n",
      "# proteins 1\n",
      "\n",
      "Kernel to optimize 0\n",
      "\n",
      "Freezing kernels\n",
      "setting grad status of kernel at 0 to 1\n",
      "setting grad status of kernel at 1 to 0\n",
      "setting grad status of kernel at 2 to 0\n",
      "setting grad status of kernel at 3 to 0\n",
      "\n",
      "\n",
      "kernels mask None\n",
      "optimizing using <class 'torch.optim.adam.Adam'> and <class 'multibind.tl.loss.MSELoss'> n_epochs 500 early_stopping 50\n",
      "lr= 0.01, weight_decay= 0.001, dir weight= 0\n",
      "Epoch: 51, Loss: 175707.976562 , best epoch: 49 secs per epoch: 0.054 s\n",
      "Epoch: 101, Loss: 175599.679688 , best epoch: 99 secs per epoch: 0.053 s\n",
      "Epoch: 151, Loss: 175561.660156 , best epoch: 149 secs per epoch: 0.053 s\n",
      "Epoch: 201, Loss: 175543.472656 , best epoch: 199 secs per epoch: 0.053 s\n",
      "Epoch: 251, Loss: 175533.371094 , best epoch: 245 secs per epoch: 0.053 s\n",
      "Epoch: 301, Loss: 175527.222656 , best epoch: 298 secs per epoch: 0.053 s\n",
      "Epoch: 351, Loss: 175520.937500 , best epoch: 349 secs per epoch: 0.053 s\n",
      "Epoch: 401, Loss: 175518.519531 , best epoch: 391 secs per epoch: 0.053 s\n",
      "Epoch: 451, Loss: 175516.500000 , best epoch: 441 secs per epoch: 0.053 s\n",
      "total time: 26.231 s\n",
      "secs per epoch: 0.053 s\n",
      "\n",
      "Kernel to optimize 1\n",
      "\n",
      "Freezing kernels\n",
      "setting grad status of kernel at 0 to 0\n",
      "setting grad status of kernel at 1 to 1\n",
      "setting grad status of kernel at 2 to 0\n",
      "setting grad status of kernel at 3 to 0\n",
      "\n",
      "\n",
      "kernels mask None\n",
      "optimizing using <class 'torch.optim.adam.Adam'> and <class 'multibind.tl.loss.MSELoss'> n_epochs 500 early_stopping 50\n",
      "lr= 0.01, weight_decay= 0.001, dir weight= 0\n",
      "Epoch: 51, Loss: 78328.708984 , best epoch: 49 secs per epoch: 0.069 s\n",
      "Epoch: 101, Loss: 78013.916016 , best epoch: 99 secs per epoch: 0.069 s\n",
      "Epoch: 151, Loss: 77923.410156 , best epoch: 149 secs per epoch: 0.068 s\n",
      "Epoch: 201, Loss: 77881.949219 , best epoch: 199 secs per epoch: 0.068 s\n",
      "Epoch: 251, Loss: 77860.343750 , best epoch: 249 secs per epoch: 0.068 s\n",
      "Epoch: 301, Loss: 77848.244141 , best epoch: 299 secs per epoch: 0.068 s\n",
      "Epoch: 351, Loss: 77839.021484 , best epoch: 349 secs per epoch: 0.068 s\n",
      "Epoch: 401, Loss: 77833.855469 , best epoch: 394 secs per epoch: 0.068 s\n",
      "Epoch: 451, Loss: 77829.328125 , best epoch: 448 secs per epoch: 0.068 s\n",
      "total time: 33.713 s\n",
      "secs per epoch: 0.068 s\n",
      "\n",
      "optimize_motif_shift (first)...\n",
      "next expand left: 1, next expand right: 1, shift: 0\n",
      "optimizing using <class 'torch.optim.adam.Adam'> and <class 'multibind.tl.loss.MSELoss'> n_epochs 500 early_stopping 50\n",
      "lr= 0.01, weight_decay= 0.001, dir weight= 0\n",
      "Epoch: 51, Loss: 77810.980469 , best epoch: 47 secs per epoch: 0.070 s\n",
      "Epoch: 101, Loss: 77810.912109 , best epoch: 80 secs per epoch: 0.069 s\n",
      "Epoch: 131, Loss: 77810.7949 , best epoch: 80 secs per epoch: 0.069 s\n",
      "early stop!\n",
      "total time: 9.018 s\n",
      "secs per epoch: 0.069 s\n",
      "after opt.\n",
      "next expand left: 1, next expand right: 2, shift: 0\n",
      "optimizing using <class 'torch.optim.adam.Adam'> and <class 'multibind.tl.loss.MSELoss'> n_epochs 500 early_stopping 50\n",
      "lr= 0.01, weight_decay= 0.001, dir weight= 0\n",
      "Epoch: 51, Loss: 77810.207031 , best epoch: 45 secs per epoch: 0.071 s\n",
      "Epoch: 96, Loss: 77811.0781 , best epoch: 45 secs per epoch: 0.070 s\n",
      "early stop!\n",
      "total time: 6.660 s\n",
      "secs per epoch: 0.070 s\n",
      "after opt.\n",
      "next expand left: 2, next expand right: 1, shift: 0\n",
      "optimizing using <class 'torch.optim.adam.Adam'> and <class 'multibind.tl.loss.MSELoss'> n_epochs 500 early_stopping 50\n",
      "lr= 0.01, weight_decay= 0.001, dir weight= 0\n",
      "Epoch: 51, Loss: 77810.937500 , best epoch: 40 secs per epoch: 0.071 s\n",
      "Epoch: 91, Loss: 77810.7461 , best epoch: 40 secs per epoch: 0.070 s\n",
      "early stop!\n",
      "total time: 6.296 s\n",
      "secs per epoch: 0.070 s\n",
      "after opt.\n",
      "next expand left: 2, next expand right: 2, shift: 0\n",
      "optimizing using <class 'torch.optim.adam.Adam'> and <class 'multibind.tl.loss.MSELoss'> n_epochs 500 early_stopping 50\n",
      "lr= 0.01, weight_decay= 0.001, dir weight= 0\n",
      "Epoch: 51, Loss: 77811.132812 , best epoch: 25 secs per epoch: 0.070 s\n",
      "Epoch: 76, Loss: 77811.3652 , best epoch: 25 secs per epoch: 0.070 s\n",
      "early stop!\n",
      "total time: 5.262 s\n",
      "secs per epoch: 0.070 s\n",
      "after opt.\n",
      "sorted\n",
      "   expand.left  expand.right  shift          loss\n",
      "0            1             2      0  77809.525391\n",
      "1            2             1      0  77809.667969\n",
      "2            1             1      0  77809.767578\n",
      "3            2             2      0  77809.939453\n",
      "4            0             0      0  77825.851562\n",
      "action: (1, 2, 0)\n",
      "\n",
      "\n",
      "optimize_motif_shift (again)...\n",
      "next expand left: 1, next expand right: 1, shift: 0\n",
      "optimizing using <class 'torch.optim.adam.Adam'> and <class 'multibind.tl.loss.MSELoss'> n_epochs 500 early_stopping 50\n",
      "lr= 0.01, weight_decay= 0.001, dir weight= 0\n",
      "Epoch: 51, Loss: 77811.078125 , best epoch: 4 secs per epoch: 0.072 s\n",
      "Epoch: 55, Loss: 77811.1875 , best epoch: 4 secs per epoch: 0.071 s\n",
      "early stop!\n",
      "total time: 3.858 s\n",
      "secs per epoch: 0.071 s\n",
      "after opt.\n",
      "sorted\n",
      "   expand.left  expand.right  shift          loss\n",
      "0            0             0      0  77809.525391\n",
      "1            1             1      0  77809.849609\n",
      "action: (0, 0, 0)\n",
      "\n",
      "\n",
      "optimize_motif_shift (first)...\n",
      "sorted\n",
      "   expand.left  expand.right  shift          loss\n",
      "0            0             0      0  77809.525391\n",
      "action: (0, 0, 0)\n",
      "\n",
      "\n",
      "\n",
      "final refinement step (after shift)...\n",
      "\n",
      "unfreezing all layers for final refinement\n",
      "kernel grad (0) = 1 \n",
      "kernel grad (1) = 1 \n",
      "kernel grad (2) = 1 \n",
      "kernel grad (3) = 1 \n",
      "\n",
      "kernels mask None\n",
      "optimizing using <class 'torch.optim.adam.Adam'> and <class 'multibind.tl.loss.MSELoss'> n_epochs 500 early_stopping 50\n",
      "lr= 0.01, weight_decay= 0.001, dir weight= 0\n",
      "Epoch: 51, Loss: 77810.873047 , best epoch: 48 secs per epoch: 0.070 s\n",
      "Epoch: 99, Loss: 77810.9609 , best epoch: 48 secs per epoch: 0.070 s\n",
      "early stop!\n",
      "total time: 6.814 s\n",
      "secs per epoch: 0.070 s\n",
      "best loss 77809.306640625\n",
      "\n",
      "Kernel to optimize 2\n",
      "\n",
      "Freezing kernels\n",
      "setting grad status of kernel at 0 to 0\n",
      "setting grad status of kernel at 1 to 0\n",
      "setting grad status of kernel at 2 to 1\n",
      "setting grad status of kernel at 3 to 0\n",
      "\n",
      "\n",
      "kernels mask None\n",
      "optimizing using <class 'torch.optim.adam.Adam'> and <class 'multibind.tl.loss.MSELoss'> n_epochs 500 early_stopping 50\n",
      "lr= 0.01, weight_decay= 0.001, dir weight= 0\n",
      "Epoch: 51, Loss: 19627.746582 , best epoch: 49 secs per epoch: 0.070 s\n",
      "Epoch: 101, Loss: 19433.491699 , best epoch: 99 secs per epoch: 0.069 s\n",
      "Epoch: 151, Loss: 19376.359863 , best epoch: 149 secs per epoch: 0.069 s\n",
      "Epoch: 201, Loss: 19351.135742 , best epoch: 199 secs per epoch: 0.069 s\n",
      "Epoch: 251, Loss: 19337.969727 , best epoch: 247 secs per epoch: 0.069 s\n",
      "Epoch: 301, Loss: 19329.408203 , best epoch: 299 secs per epoch: 0.069 s\n",
      "Epoch: 351, Loss: 19324.407715 , best epoch: 346 secs per epoch: 0.068 s\n",
      "Epoch: 401, Loss: 19320.400391 , best epoch: 399 secs per epoch: 0.068 s\n",
      "Epoch: 451, Loss: 19317.625488 , best epoch: 448 secs per epoch: 0.068 s\n",
      "total time: 33.946 s\n",
      "secs per epoch: 0.068 s\n",
      "\n",
      "optimize_motif_shift (first)...\n",
      "next expand left: 1, next expand right: 1, shift: 0\n",
      "optimizing using <class 'torch.optim.adam.Adam'> and <class 'multibind.tl.loss.MSELoss'> n_epochs 500 early_stopping 50\n",
      "lr= 0.01, weight_decay= 0.001, dir weight= 0\n",
      "Epoch: 51, Loss: 19306.340332 , best epoch: 44 secs per epoch: 0.070 s\n",
      "Epoch: 101, Loss: 19305.894531 , best epoch: 82 secs per epoch: 0.070 s\n",
      "Epoch: 151, Loss: 19305.892578 , best epoch: 110 secs per epoch: 0.069 s\n",
      "Epoch: 161, Loss: 19306.2041 , best epoch: 110 secs per epoch: 0.069 s\n",
      "early stop!\n",
      "total time: 11.100 s\n",
      "secs per epoch: 0.069 s\n",
      "after opt.\n",
      "next expand left: 1, next expand right: 2, shift: 0\n",
      "optimizing using <class 'torch.optim.adam.Adam'> and <class 'multibind.tl.loss.MSELoss'> n_epochs 500 early_stopping 50\n",
      "lr= 0.01, weight_decay= 0.001, dir weight= 0\n",
      "Epoch: 51, Loss: 19305.692871 , best epoch: 37 secs per epoch: 0.070 s\n",
      "Epoch: 101, Loss: 19306.247559 , best epoch: 98 secs per epoch: 0.070 s\n",
      "Epoch: 151, Loss: 19306.343750 , best epoch: 145 secs per epoch: 0.070 s\n",
      "Epoch: 196, Loss: 19306.0034 , best epoch: 145 secs per epoch: 0.069 s\n",
      "early stop!\n",
      "total time: 13.529 s\n",
      "secs per epoch: 0.069 s\n",
      "after opt.\n",
      "next expand left: 2, next expand right: 1, shift: 0\n",
      "optimizing using <class 'torch.optim.adam.Adam'> and <class 'multibind.tl.loss.MSELoss'> n_epochs 500 early_stopping 50\n",
      "lr= 0.01, weight_decay= 0.001, dir weight= 0\n",
      "Epoch: 51, Loss: 19305.874023 , best epoch: 38 secs per epoch: 0.071 s\n",
      "Epoch: 101, Loss: 19306.375000 , best epoch: 74 secs per epoch: 0.069 s\n",
      "Epoch: 151, Loss: 19305.895508 , best epoch: 106 secs per epoch: 0.069 s\n",
      "Epoch: 201, Loss: 19306.154785 , best epoch: 180 secs per epoch: 0.069 s\n",
      "Epoch: 231, Loss: 19305.6221 , best epoch: 180 secs per epoch: 0.069 s\n",
      "early stop!\n",
      "total time: 15.878 s\n",
      "secs per epoch: 0.069 s\n",
      "after opt.\n",
      "next expand left: 2, next expand right: 2, shift: 0\n",
      "optimizing using <class 'torch.optim.adam.Adam'> and <class 'multibind.tl.loss.MSELoss'> n_epochs 500 early_stopping 50\n",
      "lr= 0.01, weight_decay= 0.001, dir weight= 0\n",
      "Epoch: 51, Loss: 19305.997070 , best epoch: 39 secs per epoch: 0.071 s\n",
      "Epoch: 90, Loss: 19306.1089 , best epoch: 39 secs per epoch: 0.071 s\n",
      "early stop!\n",
      "total time: 6.281 s\n",
      "secs per epoch: 0.071 s\n",
      "after opt.\n",
      "sorted\n",
      "   expand.left  expand.right  shift          loss\n",
      "0            1             2      0  19305.375977\n",
      "1            2             1      0  19305.539062\n",
      "2            1             1      0  19305.559570\n",
      "3            2             2      0  19305.624023\n",
      "4            0             0      0  19315.434570\n",
      "action: (1, 2, 0)\n",
      "\n",
      "\n",
      "optimize_motif_shift (again)...\n",
      "next expand left: 1, next expand right: 1, shift: 0\n",
      "optimizing using <class 'torch.optim.adam.Adam'> and <class 'multibind.tl.loss.MSELoss'> n_epochs 500 early_stopping 50\n",
      "lr= 0.01, weight_decay= 0.001, dir weight= 0\n",
      "Epoch: 51, Loss: 19306.048340 , best epoch: 42 secs per epoch: 0.071 s\n",
      "Epoch: 101, Loss: 19306.017090 , best epoch: 99 secs per epoch: 0.070 s\n",
      "Epoch: 150, Loss: 19306.1733 , best epoch: 99 secs per epoch: 0.070 s\n",
      "early stop!\n",
      "total time: 10.469 s\n",
      "secs per epoch: 0.070 s\n",
      "after opt.\n",
      "sorted\n",
      "   expand.left  expand.right  shift          loss\n",
      "0            1             1      0  19305.361328\n",
      "1            0             0      0  19305.375977\n",
      "action: (1, 1, 0)\n",
      "\n",
      "stop. Reached maximum w...\n",
      "stop. Reached maximum w...\n",
      "\n",
      "\n",
      "final refinement step (after shift)...\n",
      "\n",
      "unfreezing all layers for final refinement\n",
      "kernel grad (0) = 1 \n",
      "kernel grad (1) = 1 \n",
      "kernel grad (2) = 1 \n",
      "kernel grad (3) = 1 \n",
      "\n",
      "kernels mask None\n",
      "optimizing using <class 'torch.optim.adam.Adam'> and <class 'multibind.tl.loss.MSELoss'> n_epochs 500 early_stopping 50\n",
      "lr= 0.01, weight_decay= 0.001, dir weight= 0\n",
      "Epoch: 51, Loss: 19305.863770 , best epoch: 22 secs per epoch: 0.071 s\n",
      "Epoch: 73, Loss: 19306.0029 , best epoch: 22 secs per epoch: 0.070 s\n",
      "early stop!\n",
      "total time: 5.050 s\n",
      "secs per epoch: 0.070 s\n",
      "best loss 19305.46728515625\n",
      "\n",
      "Kernel to optimize 3\n",
      "\n",
      "Freezing kernels\n",
      "setting grad status of kernel at 0 to 0\n",
      "setting grad status of kernel at 1 to 0\n",
      "setting grad status of kernel at 2 to 0\n",
      "setting grad status of kernel at 3 to 1\n",
      "\n",
      "\n",
      "kernels mask None\n",
      "optimizing using <class 'torch.optim.adam.Adam'> and <class 'multibind.tl.loss.MSELoss'> n_epochs 500 early_stopping 50\n",
      "lr= 0.01, weight_decay= 0.001, dir weight= 0\n",
      "Epoch: 51, Loss: 24.634100 , best epoch: 49 secs per epoch: 0.070 s\n",
      "Epoch: 101, Loss: 9.099164 , best epoch: 99 secs per epoch: 0.069 s\n",
      "Epoch: 151, Loss: 4.564031 , best epoch: 149 secs per epoch: 0.069 s\n",
      "Epoch: 201, Loss: 2.673279 , best epoch: 199 secs per epoch: 0.069 s\n",
      "Epoch: 251, Loss: 1.731016 , best epoch: 249 secs per epoch: 0.069 s\n",
      "Epoch: 301, Loss: 1.201556 , best epoch: 299 secs per epoch: 0.069 s\n",
      "Epoch: 351, Loss: 0.885302 , best epoch: 349 secs per epoch: 0.069 s\n",
      "Epoch: 401, Loss: 0.685460 , best epoch: 399 secs per epoch: 0.069 s\n",
      "Epoch: 451, Loss: 0.558777 , best epoch: 449 secs per epoch: 0.069 s\n",
      "total time: 34.211 s\n",
      "secs per epoch: 0.069 s\n",
      "\n",
      "optimize_motif_shift (first)...\n",
      "next expand left: 1, next expand right: 1, shift: 0\n",
      "optimizing using <class 'torch.optim.adam.Adam'> and <class 'multibind.tl.loss.MSELoss'> n_epochs 500 early_stopping 50\n",
      "lr= 0.01, weight_decay= 0.001, dir weight= 0\n",
      "Epoch: 51, Loss: 0.184836 , best epoch: 47 secs per epoch: 0.071 s\n",
      "Epoch: 101, Loss: 0.186368 , best epoch: 89 secs per epoch: 0.070 s\n",
      "Epoch: 151, Loss: 0.178849 , best epoch: 149 secs per epoch: 0.070 s\n",
      "Epoch: 201, Loss: 0.170452 , best epoch: 195 secs per epoch: 0.070 s\n",
      "Epoch: 251, Loss: 0.162578 , best epoch: 246 secs per epoch: 0.070 s\n",
      "Epoch: 301, Loss: 0.159897 , best epoch: 298 secs per epoch: 0.070 s\n",
      "Epoch: 351, Loss: 0.154557 , best epoch: 349 secs per epoch: 0.070 s\n",
      "Epoch: 401, Loss: 0.150966 , best epoch: 397 secs per epoch: 0.070 s\n",
      "Epoch: 451, Loss: 0.149575 , best epoch: 449 secs per epoch: 0.071 s\n",
      "total time: 35.201 s\n",
      "secs per epoch: 0.071 s\n",
      "after opt.\n",
      "next expand left: 1, next expand right: 2, shift: 0\n",
      "optimizing using <class 'torch.optim.adam.Adam'> and <class 'multibind.tl.loss.MSELoss'> n_epochs 500 early_stopping 50\n",
      "lr= 0.01, weight_decay= 0.001, dir weight= 0\n",
      "Epoch: 51, Loss: 0.185102 , best epoch: 23 secs per epoch: 0.072 s\n",
      "Epoch: 101, Loss: 0.187115 , best epoch: 89 secs per epoch: 0.072 s\n",
      "Epoch: 151, Loss: 0.174643 , best epoch: 147 secs per epoch: 0.071 s\n",
      "Epoch: 201, Loss: 0.163704 , best epoch: 197 secs per epoch: 0.071 s\n",
      "Epoch: 251, Loss: 0.143302 , best epoch: 248 secs per epoch: 0.071 s\n",
      "Epoch: 301, Loss: 0.116707 , best epoch: 295 secs per epoch: 0.071 s\n",
      "Epoch: 351, Loss: 0.116257 , best epoch: 339 secs per epoch: 0.071 s\n",
      "Epoch: 401, Loss: 0.112666 , best epoch: 390 secs per epoch: 0.071 s\n",
      "Epoch: 451, Loss: 0.114298 , best epoch: 449 secs per epoch: 0.071 s\n",
      "total time: 35.470 s\n",
      "secs per epoch: 0.071 s\n",
      "after opt.\n",
      "next expand left: 2, next expand right: 1, shift: 0\n",
      "optimizing using <class 'torch.optim.adam.Adam'> and <class 'multibind.tl.loss.MSELoss'> n_epochs 500 early_stopping 50\n",
      "lr= 0.01, weight_decay= 0.001, dir weight= 0\n",
      "Epoch: 51, Loss: 0.188613 , best epoch: 43 secs per epoch: 0.072 s\n",
      "Epoch: 101, Loss: 0.187421 , best epoch: 90 secs per epoch: 0.071 s\n",
      "Epoch: 151, Loss: 0.178857 , best epoch: 146 secs per epoch: 0.071 s\n",
      "Epoch: 201, Loss: 0.168037 , best epoch: 194 secs per epoch: 0.071 s\n",
      "Epoch: 251, Loss: 0.145001 , best epoch: 248 secs per epoch: 0.071 s\n",
      "Epoch: 301, Loss: 0.115901 , best epoch: 299 secs per epoch: 0.071 s\n",
      "Epoch: 351, Loss: 0.113836 , best epoch: 348 secs per epoch: 0.071 s\n",
      "Epoch: 401, Loss: 0.111212 , best epoch: 390 secs per epoch: 0.071 s\n",
      "Epoch: 451, Loss: 0.114382 , best epoch: 444 secs per epoch: 0.071 s\n",
      "total time: 35.338 s\n",
      "secs per epoch: 0.071 s\n",
      "after opt.\n",
      "next expand left: 2, next expand right: 2, shift: 0\n",
      "optimizing using <class 'torch.optim.adam.Adam'> and <class 'multibind.tl.loss.MSELoss'> n_epochs 500 early_stopping 50\n",
      "lr= 0.01, weight_decay= 0.001, dir weight= 0\n",
      "Epoch: 51, Loss: 0.185346 , best epoch: 32 secs per epoch: 0.072 s\n",
      "Epoch: 101, Loss: 0.185492 , best epoch: 90 secs per epoch: 0.072 s\n",
      "Epoch: 151, Loss: 0.166639 , best epoch: 149 secs per epoch: 0.072 s\n",
      "Epoch: 201, Loss: 0.166743 , best epoch: 196 secs per epoch: 0.071 s\n",
      "Epoch: 251, Loss: 0.152764 , best epoch: 242 secs per epoch: 0.071 s\n",
      "Epoch: 301, Loss: 0.152101 , best epoch: 274 secs per epoch: 0.071 s\n",
      "Epoch: 351, Loss: 0.149950 , best epoch: 334 secs per epoch: 0.071 s\n",
      "Epoch: 385, Loss: 0.1538 , best epoch: 334 secs per epoch: 0.071 s\n",
      "early stop!\n",
      "total time: 27.378 s\n",
      "secs per epoch: 0.071 s\n",
      "after opt.\n",
      "sorted\n",
      "   expand.left  expand.right  shift      loss\n",
      "0            1             2      0  0.109367\n",
      "1            2             1      0  0.109518\n",
      "2            1             1      0  0.137330\n",
      "3            2             2      0  0.149337\n",
      "4            0             0      0  0.473694\n",
      "action: (1, 2, 0)\n",
      "\n",
      "\n",
      "optimize_motif_shift (again)...\n",
      "next expand left: 1, next expand right: 1, shift: 0\n",
      "optimizing using <class 'torch.optim.adam.Adam'> and <class 'multibind.tl.loss.MSELoss'> n_epochs 500 early_stopping 50\n",
      "lr= 0.01, weight_decay= 0.001, dir weight= 0\n",
      "Epoch: 51, Loss: 0.090792 , best epoch: 49 secs per epoch: 0.073 s\n",
      "Epoch: 101, Loss: 0.083068 , best epoch: 95 secs per epoch: 0.072 s\n",
      "Epoch: 151, Loss: 0.082698 , best epoch: 135 secs per epoch: 0.072 s\n",
      "Epoch: 201, Loss: 0.081250 , best epoch: 185 secs per epoch: 0.072 s\n",
      "Epoch: 251, Loss: 0.081431 , best epoch: 238 secs per epoch: 0.072 s\n",
      "Epoch: 289, Loss: 0.0814 , best epoch: 238 secs per epoch: 0.071 s\n",
      "early stop!\n",
      "total time: 20.575 s\n",
      "secs per epoch: 0.071 s\n",
      "after opt.\n",
      "sorted\n",
      "   expand.left  expand.right  shift      loss\n",
      "0            1             1      0  0.079943\n",
      "1            0             0      0  0.109367\n",
      "action: (1, 1, 0)\n",
      "\n",
      "stop. Reached maximum w...\n",
      "stop. Reached maximum w...\n",
      "\n",
      "\n",
      "final refinement step (after shift)...\n",
      "\n",
      "unfreezing all layers for final refinement\n",
      "kernel grad (0) = 1 \n",
      "kernel grad (1) = 1 \n",
      "kernel grad (2) = 1 \n",
      "kernel grad (3) = 1 \n",
      "\n",
      "kernels mask None\n",
      "optimizing using <class 'torch.optim.adam.Adam'> and <class 'multibind.tl.loss.MSELoss'> n_epochs 500 early_stopping 50\n",
      "lr= 0.01, weight_decay= 0.001, dir weight= 0\n",
      "Epoch: 51, Loss: 0.080710 , best epoch: 17 secs per epoch: 0.072 s\n",
      "Epoch: 68, Loss: 0.0802 , best epoch: 17 secs per epoch: 0.072 s\n",
      "early stop!\n",
      "total time: 4.795 s\n",
      "secs per epoch: 0.072 s\n",
      "best loss 0.07989491894841194\n"
     ]
    }
   ],
   "source": [
    "model, best_loss = mb.tl.train_iterative(train, device, num_epochs=500, show_logo=False,\n",
    "                                         early_stopping=50, log_each=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2716831-26c0-426c-aa30-be31764d83bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: [0.0008757068052960282]\n"
     ]
    }
   ],
   "source": [
    "r2 = mb.pl.R2_calculation(model, train)\n",
    "print(\"R^2:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08d1fe92",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Multibind' object has no attribute 'conv_mono'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m mode \u001b[39min\u001b[39;00m [\u001b[39m'\u001b[39m\u001b[39msimple\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcomplex\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtriangle\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[0;32m----> 2\u001b[0m     mb\u001b[39m.\u001b[39;49mpl\u001b[39m.\u001b[39;49mconv_di(model)\n",
      "File \u001b[0;32m~/Desktop/theislab/multibind/multibind/pl/plotting.py:67\u001b[0m, in \u001b[0;36mconv_di\u001b[0;34m(model, figsize)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconv_di\u001b[39m(model, figsize\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m---> 67\u001b[0m     n_cols \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(model\u001b[39m.\u001b[39;49mconv_mono)\n\u001b[1;32m     68\u001b[0m     \u001b[39mif\u001b[39;00m figsize \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m         plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39mfigsize)\n",
      "File \u001b[0;32m~/mambaforge/envs/mubind/lib/python3.10/site-packages/torch/nn/modules/module.py:1207\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1205\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[1;32m   1206\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1207\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1208\u001b[0m     \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Multibind' object has no attribute 'conv_mono'"
     ]
    }
   ],
   "source": [
    "for mode in ['simple', 'complex', 'triangle']:\n",
    "    mb.pl.conv_di(model, mode=mode, figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a4ae89-87ca-4ae8-b509-26207cf670fe",
   "metadata": {},
   "source": [
    "# Selex (multiple datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d936cebf-9c65-46a8-85f4-203d36aaa349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prerequisites for using multiple datasets:\n",
    "# - Both datasets need to be about the same protein.\n",
    "# - They need to contain the same number of rounds.\n",
    "# - They need to have a column called \"batch\" indicating from which dataset each line comes from.\n",
    "# - The parameter labels needs to be given to SelexDataset as well.\n",
    "\n",
    "n_rounds = 1\n",
    "data1 = pd.read_csv('../data/countTable.0.CTCF_r3.tsv.gz', sep='\\t', header=None)\n",
    "data1.columns = ['seq'] + [i for i in range(n_rounds+1)]\n",
    "data1.index = data1['seq']\n",
    "del data1['seq']\n",
    "data1 = data1.sample(n=1000)\n",
    "data1[\"batch\"] = 'A'\n",
    "\n",
    "data2 = pd.read_csv('../data/countTable.0.CTCF_ESAJ_TAGCGA20NGCT.tsv.gz', sep='\\t', header=None)\n",
    "data2.columns = ['seq'] + [i for i in range(5)]\n",
    "data2.index = data2['seq']\n",
    "del data2['seq']\n",
    "data2 = data2[[i for i in range(n_rounds+1)]]\n",
    "data2 = data2[data2[0] + data2[1] > 0]\n",
    "data2 = data2.sample(n=1000)\n",
    "data2[\"batch\"] = 'B'\n",
    "\n",
    "data = pd.concat([data1, data2])\n",
    "labels = list(data1.columns[:n_rounds + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "57e6c9cd-fe61-4cdf-9944-8845783d31b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>batch</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seq</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ACGCGGAATATTAAAGTGGAGGTGACGGCC</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTAACTTGGGCTCAGATATGGCGTCTGGG</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTGTCTAGGTGAGGCACGGTCTAAGAGGCG</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GGGTTGCAGGGGGTGGGTGGTGGGATGTTA</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAGGTGTGTGTCCTGATGGGGAATGCGTGG</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAGCTACAAACTACACATAG</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GCAAGAATAGCCAAAAACGT</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CTAACGGAAAATGGCGAAGG</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CCGTGCAGCGAGCTGCCCAT</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GTAGACTGAAAGACATATCT</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                0  1 batch\n",
       "seq                                       \n",
       "ACGCGGAATATTAAAGTGGAGGTGACGGCC  1  0     A\n",
       "TTTAACTTGGGCTCAGATATGGCGTCTGGG  1  0     A\n",
       "TTGTCTAGGTGAGGCACGGTCTAAGAGGCG  1  0     A\n",
       "GGGTTGCAGGGGGTGGGTGGTGGGATGTTA  1  0     A\n",
       "AAGGTGTGTGTCCTGATGGGGAATGCGTGG  1  0     A\n",
       "...                            .. ..   ...\n",
       "CAGCTACAAACTACACATAG            0  1     B\n",
       "GCAAGAATAGCCAAAAACGT            1  0     B\n",
       "CTAACGGAAAATGGCGAAGG            0  1     B\n",
       "CCGTGCAGCGAGCTGCCCAT            1  0     B\n",
       "GTAGACTGAAAGACATATCT            0  1     B\n",
       "\n",
       "[2000 rows x 3 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data[0] + data[1] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "81355e0e-547f-491b-9ec2-c8a8d3f0af3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = mb.datasets.SelexDataset(data, n_rounds=n_rounds, labels=labels)\n",
    "train = tdata.DataLoader(dataset=dataset, batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a236198b-0845-4eb2-a809-278158bbecbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next w 15 <class 'int'>\n",
      "# rounds 1\n",
      "# batches 2\n",
      "# enr_series True\n",
      "\n",
      "Kernel to optimize 0\n",
      "\n",
      "Freezing kernels\n",
      "setting grad status of kernel at 0 to 1\n",
      "setting grad status of kernel at 1 to 0\n",
      "setting grad status of kernel at 2 to 0\n",
      "setting grad status of kernel at 3 to 0\n",
      "\n",
      "\n",
      "kernels mask None\n",
      "optimizing using <class 'torch.optim.adam.Adam'> and <class 'multibind.tl.loss.PoissonLoss'> n_epochs 500 early_stopping 50\n",
      "lr= 0.01, weight_decay= 0.001, dir weight= 0\n",
      "Epoch: 51, Loss: 0.846386 , best epoch: 49 secs per epoch: 0.100 s\n",
      "Epoch: 101, Loss: 0.844431 , best epoch: 83 secs per epoch: 0.100 s\n",
      "Epoch: 151, Loss: 0.844400 , best epoch: 126 secs per epoch: 0.099 s\n",
      "Epoch: 177, Loss: 0.8445 , best epoch: 126 secs per epoch: 0.099 s\n",
      "early stop!\n",
      "total time: 17.466 s\n",
      "secs per epoch: 0.099 s\n",
      "\n",
      "Kernel to optimize 1\n",
      "\n",
      "Freezing kernels\n",
      "setting grad status of kernel at 0 to 0\n",
      "setting grad status of kernel at 1 to 1\n",
      "setting grad status of kernel at 2 to 0\n",
      "setting grad status of kernel at 3 to 0\n",
      "\n",
      "\n",
      "kernels mask None\n",
      "optimizing using <class 'torch.optim.adam.Adam'> and <class 'multibind.tl.loss.PoissonLoss'> n_epochs 500 early_stopping 50\n",
      "lr= 0.01, weight_decay= 0.001, dir weight= 0\n",
      "Epoch: 51, Loss: 0.844463 , best epoch: 3 secs per epoch: 0.114 s\n",
      "Epoch: 54, Loss: 0.8444 , best epoch: 3 secs per epoch: 0.114 s\n",
      "early stop!\n",
      "total time: 6.062 s\n",
      "secs per epoch: 0.114 s\n",
      "\n",
      "optimize_motif_shift (first)...\n",
      "next expand left: 1, next expand right: 1, shift: 0\n",
      "optimizing using <class 'torch.optim.adam.Adam'> and <class 'multibind.tl.loss.PoissonLoss'> n_epochs 500 early_stopping 50\n",
      "lr= 0.01, weight_decay= 0.001, dir weight= 0\n",
      "Epoch: 51, Loss: 0.844381 , best epoch: 2 secs per epoch: 0.085 s\n",
      "Epoch: 53, Loss: 0.8444 , best epoch: 2 secs per epoch: 0.085 s\n",
      "early stop!\n",
      "total time: 4.425 s\n",
      "secs per epoch: 0.085 s\n",
      "after opt.\n",
      "next expand left: 1, next expand right: 2, shift: 0\n",
      "optimizing using <class 'torch.optim.adam.Adam'> and <class 'multibind.tl.loss.PoissonLoss'> n_epochs 500 early_stopping 50\n",
      "lr= 0.01, weight_decay= 0.001, dir weight= 0\n",
      "Epoch: 51, Loss: 0.844697 , best epoch: 19 secs per epoch: 0.085 s\n",
      "Epoch: 70, Loss: 0.8445 , best epoch: 19 secs per epoch: 0.085 s\n",
      "early stop!\n",
      "total time: 5.898 s\n",
      "secs per epoch: 0.085 s\n",
      "after opt.\n",
      "next expand left: 2, next expand right: 1, shift: 0\n",
      "optimizing using <class 'torch.optim.adam.Adam'> and <class 'multibind.tl.loss.PoissonLoss'> n_epochs 500 early_stopping 50\n",
      "lr= 0.01, weight_decay= 0.001, dir weight= 0\n",
      "Epoch: 51, Loss: 0.844269 , best epoch: 3 secs per epoch: 0.083 s\n",
      "Epoch: 54, Loss: 0.8443 , best epoch: 3 secs per epoch: 0.083 s\n",
      "early stop!\n",
      "total time: 4.379 s\n",
      "secs per epoch: 0.083 s\n",
      "after opt.\n",
      "next expand left: 2, next expand right: 2, shift: 0\n",
      "optimizing using <class 'torch.optim.adam.Adam'> and <class 'multibind.tl.loss.PoissonLoss'> n_epochs 500 early_stopping 50\n",
      "lr= 0.01, weight_decay= 0.001, dir weight= 0\n",
      "Epoch: 51, Loss: 0.844408 , best epoch: 4 secs per epoch: 0.082 s\n",
      "Epoch: 55, Loss: 0.8443 , best epoch: 4 secs per epoch: 0.082 s\n",
      "early stop!\n",
      "total time: 4.438 s\n",
      "secs per epoch: 0.082 s\n",
      "after opt.\n",
      "sorted\n",
      "   expand.left  expand.right  shift      loss\n",
      "0            0             0      0  0.843921\n",
      "1            1             2      0  0.844106\n",
      "2            2             1      0  0.844109\n",
      "3            2             2      0  0.844161\n",
      "4            1             1      0  0.844182\n",
      "action: (0, 0, 0)\n",
      "\n",
      "\n",
      "optimize_motif_shift (first)...\n",
      "sorted\n",
      "   expand.left  expand.right  shift      loss\n",
      "0            0             0      0  0.843921\n",
      "action: (0, 0, 0)\n",
      "\n",
      "\n",
      "\n",
      "final refinement step (after shift)...\n",
      "\n",
      "unfreezing all layers for final refinement\n",
      "kernel grad (0) = 1 \n",
      "kernel grad (1) = 1 \n",
      "kernel grad (2) = 1 \n",
      "kernel grad (3) = 1 \n",
      "\n",
      "kernels mask None\n",
      "optimizing using <class 'torch.optim.adam.Adam'> and <class 'multibind.tl.loss.PoissonLoss'> n_epochs 500 early_stopping 50\n",
      "lr= 0.01, weight_decay= 0.001, dir weight= 0\n",
      "Epoch: 51, Loss: 0.844347 , best epoch: 30 secs per epoch: 0.113 s\n",
      "Epoch: 81, Loss: 0.8445 , best epoch: 30 secs per epoch: 0.113 s\n",
      "early stop!\n",
      "total time: 9.040 s\n",
      "secs per epoch: 0.113 s\n",
      "best loss 0.8441103026270866\n",
      "\n",
      "Kernel to optimize 2\n",
      "\n",
      "Freezing kernels\n",
      "setting grad status of kernel at 0 to 0\n",
      "setting grad status of kernel at 1 to 0\n",
      "setting grad status of kernel at 2 to 1\n",
      "setting grad status of kernel at 3 to 0\n",
      "\n",
      "\n",
      "kernels mask None\n",
      "optimizing using <class 'torch.optim.adam.Adam'> and <class 'multibind.tl.loss.PoissonLoss'> n_epochs 500 early_stopping 50\n",
      "lr= 0.01, weight_decay= 0.001, dir weight= 0\n",
      "Epoch: 51, Loss: 0.844364 , best epoch: 12 secs per epoch: 0.116 s\n",
      "Epoch: 63, Loss: 0.8442 , best epoch: 12 secs per epoch: 0.116 s\n",
      "early stop!\n",
      "total time: 7.170 s\n",
      "secs per epoch: 0.116 s\n",
      "\n",
      "optimize_motif_shift (first)...\n",
      "next expand left: 1, next expand right: 1, shift: 0\n",
      "optimizing using <class 'torch.optim.adam.Adam'> and <class 'multibind.tl.loss.PoissonLoss'> n_epochs 500 early_stopping 50\n",
      "lr= 0.01, weight_decay= 0.001, dir weight= 0\n",
      "Epoch: 51, Loss: 0.844114 , best epoch: 2 secs per epoch: 0.082 s\n",
      "Epoch: 53, Loss: 0.8443 , best epoch: 2 secs per epoch: 0.082 s\n",
      "early stop!\n",
      "total time: 4.256 s\n",
      "secs per epoch: 0.082 s\n",
      "after opt.\n",
      "next expand left: 1, next expand right: 2, shift: 0\n",
      "optimizing using <class 'torch.optim.adam.Adam'> and <class 'multibind.tl.loss.PoissonLoss'> n_epochs 500 early_stopping 50\n",
      "lr= 0.01, weight_decay= 0.001, dir weight= 0\n",
      "Epoch: 51, Loss: 0.844466 , best epoch: 1 secs per epoch: 0.082 s\n",
      "Epoch: 52, Loss: 0.8446 , best epoch: 1 secs per epoch: 0.082 s\n",
      "early stop!\n",
      "total time: 4.195 s\n",
      "secs per epoch: 0.082 s\n",
      "after opt.\n",
      "next expand left: 2, next expand right: 1, shift: 0\n",
      "optimizing using <class 'torch.optim.adam.Adam'> and <class 'multibind.tl.loss.PoissonLoss'> n_epochs 500 early_stopping 50\n",
      "lr= 0.01, weight_decay= 0.001, dir weight= 0\n",
      "Epoch: 51, Loss: 0.844121 , best epoch: 31 secs per epoch: 0.084 s\n",
      "Epoch: 101, Loss: 0.844326 , best epoch: 83 secs per epoch: 0.083 s\n",
      "Epoch: 134, Loss: 0.8444 , best epoch: 83 secs per epoch: 0.083 s\n",
      "early stop!\n",
      "total time: 11.070 s\n",
      "secs per epoch: 0.083 s\n",
      "after opt.\n",
      "next expand left: 2, next expand right: 2, shift: 0\n",
      "optimizing using <class 'torch.optim.adam.Adam'> and <class 'multibind.tl.loss.PoissonLoss'> n_epochs 500 early_stopping 50\n",
      "lr= 0.01, weight_decay= 0.001, dir weight= 0\n",
      "Epoch: 51, Loss: 0.844354 , best epoch: 21 secs per epoch: 0.085 s\n",
      "Epoch: 72, Loss: 0.8442 , best epoch: 21 secs per epoch: 0.084 s\n",
      "early stop!\n",
      "total time: 5.979 s\n",
      "secs per epoch: 0.084 s\n",
      "after opt.\n",
      "sorted\n",
      "   expand.left  expand.right  shift      loss\n",
      "0            0             0      0  0.843959\n",
      "1            1             2      0  0.844009\n",
      "2            2             1      0  0.844079\n",
      "3            2             2      0  0.844084\n",
      "4            1             1      0  0.844092\n",
      "action: (0, 0, 0)\n",
      "\n",
      "\n",
      "optimize_motif_shift (first)...\n",
      "sorted\n",
      "   expand.left  expand.right  shift      loss\n",
      "0            0             0      0  0.843959\n",
      "action: (0, 0, 0)\n",
      "\n",
      "\n",
      "\n",
      "final refinement step (after shift)...\n",
      "\n",
      "unfreezing all layers for final refinement\n",
      "kernel grad (0) = 1 \n",
      "kernel grad (1) = 1 \n",
      "kernel grad (2) = 1 \n",
      "kernel grad (3) = 1 \n",
      "\n",
      "kernels mask None\n",
      "optimizing using <class 'torch.optim.adam.Adam'> and <class 'multibind.tl.loss.PoissonLoss'> n_epochs 500 early_stopping 50\n",
      "lr= 0.01, weight_decay= 0.001, dir weight= 0\n",
      "Epoch: 51, Loss: 0.844220 , best epoch: 2 secs per epoch: 0.120 s\n",
      "Epoch: 53, Loss: 0.8443 , best epoch: 2 secs per epoch: 0.120 s\n",
      "early stop!\n",
      "total time: 6.245 s\n",
      "secs per epoch: 0.120 s\n",
      "best loss 0.8439928442239761\n",
      "\n",
      "Kernel to optimize 3\n",
      "\n",
      "Freezing kernels\n",
      "setting grad status of kernel at 0 to 0\n",
      "setting grad status of kernel at 1 to 0\n",
      "setting grad status of kernel at 2 to 0\n",
      "setting grad status of kernel at 3 to 1\n",
      "\n",
      "\n",
      "kernels mask None\n",
      "optimizing using <class 'torch.optim.adam.Adam'> and <class 'multibind.tl.loss.PoissonLoss'> n_epochs 500 early_stopping 50\n",
      "lr= 0.01, weight_decay= 0.001, dir weight= 0\n",
      "Epoch: 51, Loss: 0.843836 , best epoch: 30 secs per epoch: 0.120 s\n",
      "Epoch: 81, Loss: 0.8440 , best epoch: 30 secs per epoch: 0.119 s\n",
      "early stop!\n",
      "total time: 9.506 s\n",
      "secs per epoch: 0.119 s\n",
      "\n",
      "optimize_motif_shift (first)...\n",
      "next expand left: 1, next expand right: 1, shift: 0\n",
      "optimizing using <class 'torch.optim.adam.Adam'> and <class 'multibind.tl.loss.PoissonLoss'> n_epochs 500 early_stopping 50\n",
      "lr= 0.01, weight_decay= 0.001, dir weight= 0\n",
      "Epoch: 51, Loss: 0.844108 , best epoch: 18 secs per epoch: 0.080 s\n",
      "Epoch: 69, Loss: 0.8442 , best epoch: 18 secs per epoch: 0.079 s\n",
      "early stop!\n",
      "total time: 5.370 s\n",
      "secs per epoch: 0.079 s\n",
      "after opt.\n",
      "next expand left: 1, next expand right: 2, shift: 0\n",
      "optimizing using <class 'torch.optim.adam.Adam'> and <class 'multibind.tl.loss.PoissonLoss'> n_epochs 500 early_stopping 50\n",
      "lr= 0.01, weight_decay= 0.001, dir weight= 0\n",
      "Epoch: 51, Loss: 0.843934 , best epoch: 6 secs per epoch: 0.078 s\n",
      "Epoch: 57, Loss: 0.8440 , best epoch: 6 secs per epoch: 0.078 s\n",
      "early stop!\n",
      "total time: 4.379 s\n",
      "secs per epoch: 0.078 s\n",
      "after opt.\n",
      "next expand left: 2, next expand right: 1, shift: 0\n",
      "optimizing using <class 'torch.optim.adam.Adam'> and <class 'multibind.tl.loss.PoissonLoss'> n_epochs 500 early_stopping 50\n",
      "lr= 0.01, weight_decay= 0.001, dir weight= 0\n",
      "Epoch: 51, Loss: 0.844007 , best epoch: 39 secs per epoch: 0.081 s\n",
      "Epoch: 90, Loss: 0.8439 , best epoch: 39 secs per epoch: 0.080 s\n",
      "early stop!\n",
      "total time: 7.122 s\n",
      "secs per epoch: 0.080 s\n",
      "after opt.\n",
      "next expand left: 2, next expand right: 2, shift: 0\n",
      "optimizing using <class 'torch.optim.adam.Adam'> and <class 'multibind.tl.loss.PoissonLoss'> n_epochs 500 early_stopping 50\n",
      "lr= 0.01, weight_decay= 0.001, dir weight= 0\n",
      "Epoch: 51, Loss: 0.843773 , best epoch: 4 secs per epoch: 0.081 s\n",
      "Epoch: 55, Loss: 0.8441 , best epoch: 4 secs per epoch: 0.080 s\n",
      "early stop!\n",
      "total time: 4.332 s\n",
      "secs per epoch: 0.080 s\n",
      "after opt.\n",
      "sorted\n",
      "   expand.left  expand.right  shift      loss\n",
      "0            1             1      0  0.843727\n",
      "1            2             2      0  0.843728\n",
      "2            2             1      0  0.843758\n",
      "3            0             0      0  0.843795\n",
      "4            1             2      0  0.843838\n",
      "action: (1, 1, 0)\n",
      "\n",
      "\n",
      "optimize_motif_shift (again)...\n",
      "next expand left: 1, next expand right: 1, shift: 0\n",
      "optimizing using <class 'torch.optim.adam.Adam'> and <class 'multibind.tl.loss.PoissonLoss'> n_epochs 500 early_stopping 50\n",
      "lr= 0.01, weight_decay= 0.001, dir weight= 0\n",
      "Epoch: 51, Loss: 0.843900 , best epoch: 33 secs per epoch: 0.082 s\n",
      "Epoch: 101, Loss: 0.844167 , best epoch: 76 secs per epoch: 0.082 s\n",
      "Epoch: 127, Loss: 0.8442 , best epoch: 76 secs per epoch: 0.082 s\n",
      "early stop!\n",
      "total time: 10.386 s\n",
      "secs per epoch: 0.082 s\n",
      "after opt.\n",
      "next expand left: 1, next expand right: 2, shift: 0\n",
      "optimizing using <class 'torch.optim.adam.Adam'> and <class 'multibind.tl.loss.PoissonLoss'> n_epochs 500 early_stopping 50\n",
      "lr= 0.01, weight_decay= 0.001, dir weight= 0\n",
      "Epoch: 51, Loss: 0.844218 , best epoch: 7 secs per epoch: 0.085 s\n",
      "Epoch: 58, Loss: 0.8444 , best epoch: 7 secs per epoch: 0.085 s\n",
      "early stop!\n",
      "total time: 4.850 s\n",
      "secs per epoch: 0.085 s\n",
      "after opt.\n",
      "next expand left: 2, next expand right: 1, shift: 0\n",
      "optimizing using <class 'torch.optim.adam.Adam'> and <class 'multibind.tl.loss.PoissonLoss'> n_epochs 500 early_stopping 50\n",
      "lr= 0.01, weight_decay= 0.001, dir weight= 0\n",
      "Epoch: 51, Loss: 0.843803 , best epoch: 3 secs per epoch: 0.084 s\n",
      "Epoch: 101, Loss: 0.843865 , best epoch: 86 secs per epoch: 0.084 s\n",
      "Epoch: 137, Loss: 0.8439 , best epoch: 86 secs per epoch: 0.084 s\n",
      "early stop!\n",
      "total time: 11.453 s\n",
      "secs per epoch: 0.084 s\n",
      "after opt.\n",
      "sorted\n",
      "   expand.left  expand.right  shift      loss\n",
      "0            1             2      0  0.843726\n",
      "1            0             0      0  0.843727\n",
      "2            2             1      0  0.843732\n",
      "3            1             1      0  0.843764\n",
      "action: (1, 2, 0)\n",
      "\n",
      "stop. Reached maximum w...\n",
      "stop. Reached maximum w...\n",
      "\n",
      "\n",
      "final refinement step (after shift)...\n",
      "\n",
      "unfreezing all layers for final refinement\n",
      "kernel grad (0) = 1 \n",
      "kernel grad (1) = 1 \n",
      "kernel grad (2) = 1 \n",
      "kernel grad (3) = 1 \n",
      "\n",
      "kernels mask None\n",
      "optimizing using <class 'torch.optim.adam.Adam'> and <class 'multibind.tl.loss.PoissonLoss'> n_epochs 500 early_stopping 50\n",
      "lr= 0.01, weight_decay= 0.001, dir weight= 0\n",
      "Epoch: 51, Loss: 0.844261 , best epoch: 26 secs per epoch: 0.086 s\n",
      "Epoch: 101, Loss: 0.844079 , best epoch: 62 secs per epoch: 0.085 s\n",
      "Epoch: 113, Loss: 0.8440 , best epoch: 62 secs per epoch: 0.085 s\n",
      "early stop!\n",
      "total time: 9.544 s\n",
      "secs per epoch: 0.085 s\n",
      "best loss 0.8436425626277924\n"
     ]
    }
   ],
   "source": [
    "model, best_loss = mb.tl.train_iterative(train, device, num_epochs=500, show_logo=False, \n",
    "                                         early_stopping=50, log_each=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1e12a634-91e8-4dbc-bd20-1b4b6f3fe461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: [0.010105660487551682]\n"
     ]
    }
   ],
   "source": [
    "r2 = mb.pl.R2_calculation(model, train)\n",
    "print(\"R^2:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c4dd81ca-a465-427b-8b81-560e9fb385f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Multibind(\n",
       "  (padding): ConstantPad2d(padding=(14, 14, 0, 0), value=0.25)\n",
       "  (binding_modes): BindingModesSimple(\n",
       "    (conv_mono): ModuleList(\n",
       "      (0): None\n",
       "      (1): Conv2d(1, 1, kernel_size=(4, 15), stride=(1, 1), bias=False)\n",
       "      (2): Conv2d(1, 1, kernel_size=(4, 15), stride=(1, 1), bias=False)\n",
       "      (3): Conv2d(1, 1, kernel_size=(4, 15), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (conv_di): ModuleList(\n",
       "      (0): None\n",
       "      (1): Conv2d(1, 1, kernel_size=(16, 15), stride=(1, 1), bias=False)\n",
       "      (2): Conv2d(1, 1, kernel_size=(16, 15), stride=(1, 1), bias=False)\n",
       "      (3): Conv2d(1, 1, kernel_size=(16, 15), stride=(1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (activities): ActivitiesSimple(\n",
       "    (log_activities): ParameterList(\n",
       "        (0): Parameter containing: [torch.FloatTensor of size 2x2]\n",
       "        (1): Parameter containing: [torch.FloatTensor of size 2x2]\n",
       "        (2): Parameter containing: [torch.FloatTensor of size 2x2]\n",
       "        (3): Parameter containing: [torch.FloatTensor of size 2x2]\n",
       "    )\n",
       "  )\n",
       "  (selex_module): SelexModule()\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mubind",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 | packaged by conda-forge | (main, Aug 22 2022, 20:38:29) [Clang 13.0.1 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "598830fe471ad270c8799031f2ac384ffcd0e141210cbf2b0994cc2f8665407f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
