{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import seaborn\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import mubind as mb"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "working_dir = os.path.expanduser('~/workspace/theislab/mubind/docs/notebooks/scatac')\n",
    "if os.path.exists(working_dir):\n",
    "    os.chdir(working_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import itertools\n",
    "import glob\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import bindome as bd\n",
    "bd.constants.ANNOTATIONS_DIRECTORY = '../../../annotations'\n",
    "import torch\n",
    "import mubind as mb\n",
    "from tqdm.notebook import tqdm_notebook as tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pwms = mb.datasets.genre()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import random\n",
    "# reduced_groups = [p.to_numpy() for p in random.sample(pwms, 20) if p.shape[-1] != 0]\n",
    "# reduced_groups\n",
    "# reduced_groups = mb.tl.reduce_filters([p.to_numpy() for p in pwms[:10]], thr_group=0.03, plot=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "reduced_groups = [p.to_numpy() for p in pwms]\n",
    "print(len(reduced_groups))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# reduced_groups = reduced_groups[:4]\n",
    "# reduced_groups = reduced_groups[:1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "criterion = mb.tl.PoissonLoss()\n",
    "\n",
    "n_rounds = 1\n",
    "n_batches = 100\n",
    "enr_series = 0\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = mb.models.Multibind(\n",
    "    datatype=\"selex\",\n",
    "    kernels=[0] + [m.shape[-1] for m in reduced_groups],\n",
    "    n_rounds=n_rounds,\n",
    "    init_random=False,\n",
    "    n_batches=n_batches,\n",
    "    enr_series=enr_series,\n",
    "    use_dinuc=False,\n",
    "    dinuc_mode=None# 'full',\n",
    ").to(device)\n",
    "\n",
    "model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for i, mono_best in enumerate(reduced_groups):\n",
    "    if mono_best.shape[-1] == 0:\n",
    "        continue\n",
    "    # print(mono_best.shape, model.binding_modes.conv_mono[i + 1].weight.shape)\n",
    "    # print(model.binding_modes.conv_mono[i + 1].weight.device)\n",
    "    new_w = mono_best.reshape([1, 1] + list(mono_best.shape))\n",
    "    model.binding_modes.conv_mono[i + 1].weight = torch.nn.Parameter(torch.tensor(new_w, dtype=torch.float))\n",
    "    # print(model.binding_modes.conv_mono[i + 1].weight.device)\n",
    "# move the model a final time to the GPU\n",
    "model = model.to(device)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device: \" + str(device))\n",
    "\n",
    "# suppress numba deprecations warnings\n",
    "from numba.core.errors import NumbaDeprecationWarning, NumbaPendingDeprecationWarning\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter('ignore', category=NumbaDeprecationWarning)\n",
    "warnings.simplefilter('ignore', category=NumbaPendingDeprecationWarning)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for pi, p in enumerate(reduced_groups):\n",
    "    print(pi, p.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mb.pl.set_rcParams({'figure.figsize': [15, 3], 'figure.dpi': 90})\n",
    "mb.pl.conv(model, title=False, xticks=False, rowspan_dinuc=0, rowspan_mono=1, n_rows=5, n_cols=12) # n_cols=len(reduced_groups))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def unfreeze(model, feat_lab=None, position=None):\n",
    "    # block mononucleotide but free dinucleotide and activities to calibrate themselves during training\n",
    "    verbose = 1\n",
    "    for ki in range(2 + 1):\n",
    "        mask_pos = (ki == position if position is not None else True)\n",
    "        mask_mono = (feat_lab == 'mono') and mask_pos\n",
    "        mask_dinuc = (feat_lab == 'dinuc') and mask_pos\n",
    "        if verbose != 0:\n",
    "            print(\"setting grad status of kernel (mono, dinuc) at %i to (%i, %i)\" % (ki, mask_mono, mask_dinuc))\n",
    "        model.binding_modes.update_grad_mono(ki, mask_mono)\n",
    "        model.binding_modes.update_grad_di(ki, mask_dinuc)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Freeze weights and train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# unfreeze(model, None)\n",
    "# model.binding_modes.update_grad_mono(0, True)\n",
    "# model.binding_modes.update_grad_di(0, True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cd ~/workspace/theislab/mubind/notebooks/scatac"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import mubind as mb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import bindome as bd\n",
    "bd.constants.ANNOTATIONS_DIRECTORY = 'annotations'\n",
    "# mb.models.MultiBind\n",
    "import torch.optim as topti\n",
    "import torch.utils.data as tdata\n",
    "import matplotlib.pyplot as plt\n",
    "import logomaker\n",
    "import os\n",
    "import scipy\n",
    "import pickle\n",
    "\n",
    "# Use a GPU if available, as it should be faster.\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device: \" + str(device))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "atac_path = '../../../annotations/scatac/pancreas_multiome_2022_processed_sample_c16918_p50000.h5ad'\n",
    "os.path.exists(atac_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!ls -ltrh ../../../annotations/scatac/"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "adata = sc.read_h5ad(atac_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "adata.X.sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "adata.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "adata = adata[:,adata.var.modality == 'ATAC'].copy()\n",
    "\n",
    "n_sample_cells = 250\n",
    "n_sample_peaks = 100\n",
    "obs_sample = pd.Series(adata.obs_names).sample(n_sample_cells)\n",
    "var_sample = pd.Series(adata.var_names).sample(n_sample_peaks)\n",
    "\n",
    "ad = adata[adata.obs_names.isin(obs_sample),adata.var_names.isin(var_sample)]\n",
    "ad.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sc.pl.umap(ad)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ad.var['chr'] = 'chr' + ad.var_names.str.split('-').str[0]\n",
    "ad.var['start'] = ad.var_names.str.split('-').str[1].astype(int)\n",
    "ad.var['end'] = ad.var_names.str.split('-').str[2].astype(int)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "extend = 50\n",
    "\n",
    "ad.var['chr'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ad.var['summit'] = ((ad.var['end'] + ad.var['start']) / 2).astype(int)\n",
    "ad.var['summit.start'] = ad.var['summit'] - extend\n",
    "ad.var['summit.end'] = ad.var['summit'] + extend\n",
    "ad.var['k.summit'] = ad.var['chr'] + ':' + ad.var['summit.start'].astype(str) + '-' + ad.var['summit.end'].astype(str)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_seqs = 10000 # adata.shape[1] # None # 1000\n",
    "seqs = mb.bindome.tl.get_sequences_from_bed(ad.var[['chr', 'summit.start', 'summit.end']].head(n_seqs), genome='mm10', uppercase=True,\n",
    "                                            gen_path='../../../annotations/mm10/genome/mm10.fa')\n",
    "keys = set([s[0] for s in seqs])\n",
    "ad = ad[:,ad.var['k.summit'].isin(keys)]\n",
    "# seqs = [[s[0], s[1].upper()] for s in seqs[0]]\n",
    "len(seqs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# remove Ns\n",
    "for s in seqs:\n",
    "    if 'N' in s:\n",
    "        assert False\n",
    "    # seqs = [[s[0], s[1].replace('N', '')] for s in seqs]\n",
    "counts = ad.X.T"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "next_data = pd.DataFrame(counts.A) # sparse.from_spmatrix(counts.A)\n",
    "next_data['var'] = next_data.var(axis=1)\n",
    "# next_data = next_data[range(100)].copy()\n",
    "next_data.index = [s[1] for s in seqs]\n",
    "next_data.index.name = 'seq'\n",
    "next_data.shape\n",
    "# sum_index = next_data[next_data.columns[:-1]].var(axis=1).sort_values(ascending=False).index\n",
    "n_cells = 10000\n",
    "top_var = next_data[['var']].sort_values('var', ascending=False).index[:n_cells]\n",
    "# next_data = next_data.head(10000)\n",
    "next_data_sel = next_data.reindex(top_var) # .reset_index(drop=True)\n",
    "next_data_sel\n",
    "del next_data_sel['var']\n",
    "# next_data_sel.index = next_data_sel['seq']\n",
    "# del next_data_sel['seq']\n",
    "\n",
    "df = next_data_sel.copy() # sample\n",
    "# df = df[df.columns[:5000]] # .head(100) # sample\n",
    "\n",
    "# shorten sequences/remove duplicates\n",
    "# df.index = df.index.astype(str).str[35:-35]\n",
    "# df = df[~df.index.duplicated(keep='first')]\n",
    "\n",
    "zero_counts = df.sum(axis=1) == 0\n",
    "df = df[~zero_counts] # remove zeroes\n",
    "\n",
    "df.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df2 = df.reset_index().melt('seq').set_index('seq')\n",
    "# add a baseline count\n",
    "df2[0] = 1.0\n",
    "cols = ['batch', 1, 0]\n",
    "df2.columns = cols\n",
    "df2 = df2[[0, 1, 'batch']] # cols[::-1]]\n",
    "df2['batch'] = df2['batch'].astype(int)\n",
    "print(df2.shape)\n",
    "print(len(set(df2['batch'])))\n",
    "n_cells = 200\n",
    "df2 = df2[df2['batch'].isin(range(0, n_cells))]\n",
    "print(df2['batch'].value_counts())\n",
    "df2.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### This is the relatedness graph and used for dynamics filters learning"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset = mb.datasets.SelexDataset(df, n_rounds=df.shape[1], enr_series=False)\n",
    "len(set(dataset.batch))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_batch = len(set(dataset.batch))\n",
    "n_batch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train = tdata.DataLoader(dataset=dataset, batch_size=1024, shuffle=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "b = np.random.randint(0, 2, (3, 4))\n",
    "conn = np.random.randint(0, 2, (4, 4))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_kernels = len(reduced_groups)\n",
    "# n_kernels = 8"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch.optim as topti\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "ad\n",
    "criterion = mb.tl.PoissonLoss()\n",
    "\n",
    "w = [r.shape[1] for r in reduced_groups]\n",
    "model = mb.models.Multibind.make_model(train, n_kernels, criterion, kernels=[0, 2] + w,\n",
    "                                       # use_dinuc=True, dinuc_mode='full',\n",
    "                                       optimize_sym_weight=False,\n",
    "                                       optimize_exp_barrier=True,\n",
    "                                       optimize_log_dynamic=False,\n",
    "                                       use_dinuc=False,\n",
    "                                       device=device,\n",
    "                                       dinuc_mode=None) # .cuda()\n",
    "\n",
    "# initialize the reduce kernels\n",
    "for i, mono_best in enumerate(reduced_groups):\n",
    "    if mono_best.shape[-1] == 0:\n",
    "        continue\n",
    "    # print(mono_best.shape, model.binding_modes.conv_mono[i + 1].weight.shape)\n",
    "    # print(model.binding_modes.conv_mono[i + 1].weight.device)\n",
    "    new_w = mono_best.reshape([1, 1] + list(mono_best.shape))\n",
    "    model.binding_modes.conv_mono[i + 1].weight = torch.nn.Parameter(torch.tensor(new_w, dtype=torch.float))\n",
    "    # print(model.binding_modes.conv_mono[i + 1].weight.device)\n",
    "# move the model a final time to the GPU\n",
    "model = model.to(device)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.prepare_knn(ad)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mb.pl.set_rcParams({'figure.figsize': [15, 3], 'figure.dpi': 90})\n",
    "mb.pl.conv(model, title=False, xticks=False, rowspan_dinuc=0, rowspan_mono=1, n_rows=10, n_cols=12) # n_cols=len(reduced_groups))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('ready to train')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mb.pl.set_rcParams({'figure.figsize': [20, 5], 'figure.dpi': 100})\n",
    "# mb.pl.conv(model, n_cols=2)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.prepare_knn(ad)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('here...')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ad.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model, best_loss = model.optimize_iterative(train, n_epochs=[1500] + [200] * (n_kernels + 1), show_logo=False, use_mono=True, use_dinuc=False, dinuc_mode='local',\n",
    "                                            opt_kernel_shift=[0, 0] + [0] * (n_kernels),\n",
    "                                            opt_kernel_length=[0, 0] + [0] * (n_kernels),\n",
    "                                            shift_max=1, shift_step=1, optimiser=topti.Adam,\n",
    "                                            skip_kernels=range(1, 120),\n",
    "                                            n_batches=1, n_rounds=2, num_epochs_shift_factor=1, # log_etas=log_etas, # log_etas=log_etas,\n",
    "                                            kernels = [0] + [2] + [20] * (n_kernels), r2_per_epoch=True,\n",
    "                                            exp_max=8,\n",
    "                                            early_stopping=50, log_each=10, w=20, max_w=20) #  target_dim=train.dataset.signal.shape[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.subplot(1, 4, 1)\n",
    "plt.plot(model.loss_history_log_dynamic)\n",
    "plt.ylabel('log dynamic loss')\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.plot(model.loss_history)\n",
    "plt.ylabel('overall loss')\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.plot(model.loss_history_sym_weights)\n",
    "plt.ylabel('similar weights loss')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from matplotlib import rcParams\n",
    "rcParams['figure.figsize'] = 20, 5\n",
    "rcParams['figure.dpi'] = 100\n",
    "mb.pl.conv(model, n_cols=12, n_rows=10, show=True)\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tsum = torch.sum\n",
    "texp = torch.exp\n",
    "tspa = torch.sparse_coo_tensor\n",
    "tsmm = torch.sparse.mm\n",
    "t = torch.transpose\n",
    "\n",
    "# connectivities\n",
    "C = model.selex_module.conn_sparse\n",
    "a_ind = C.indices()\n",
    "\n",
    "log_dynamic = model.selex_module.log_dynamic\n",
    "D = model.selex_module.log_dynamic\n",
    "D_tril = tspa(a_ind, D, C.shape)  # .requires_grad_(True).cuda()\n",
    "D_triu = tspa(a_ind, -D, C.shape)  # .requires_grad_(True).cuda()\n",
    "D = D_tril + t(D_triu, 0, 1)\n",
    "# log_dynamic = log_dynamic + -torch.transpose(log_dynamic, 0, 1)\n",
    "# triu_indices = torch.triu_indices(row=n_rounds, col=n_rounds, offset=1)\n",
    "D"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "mb.pl.set_rcParams({'figure.figsize': [3, 3]})\n",
    "sns.heatmap(D.to_dense().detach().cpu(), cmap='RdBu_r')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.best_r2_by_new_filter"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# contributions per newly added kernel\n",
    "rcParams['figure.figsize'] = 2, 3\n",
    "rcParams['figure.dpi'] = 80\n",
    "import seaborn as sns\n",
    "r2 = pd.DataFrame(model.best_r2_by_new_filter, columns=['r2']).reset_index()\n",
    "sns.barplot(data=r2, x='index', y='r2')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# contributions per newly added kernel\n",
    "rcParams['figure.figsize'] = 2, 3\n",
    "rcParams['figure.dpi'] = 80\n",
    "import seaborn as sns\n",
    "r2 = pd.DataFrame(model.best_r2_by_new_filter, columns=['r2']).reset_index()\n",
    "sns.barplot(data=r2, x='index', y='r2')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.set_printoptions(precision=2)\n",
    "dynamic_score = D.to_dense().detach().cpu().sum(axis=0)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# dyn_score\n",
    "dynamic_score = dynamic_score\n",
    "dynamic_score = (dynamic_score - dynamic_score.min()) / (dynamic_score.max() - dynamic_score.min())\n",
    "ad.obs['dynamic_score'] = dynamic_score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ad.obs['dynamic_score_cluster'] = np.where(dynamic_score > dynamic_score.mean(), 'dynamic', 'static')\n",
    "z1 = np.where(((dynamic_score - dynamic_score.mean()) / dynamic_score.std()) > 1, 'dynamic', 'static')\n",
    "z2 = np.where(((dynamic_score - dynamic_score.mean()) / dynamic_score.std()) > 2, 'dynamic', 'static')\n",
    "\n",
    "ad.obs['dynamic_score_z1'] = z1\n",
    "ad.obs['dynamic_score_z2'] = z2\n",
    "\n",
    "#  ad.obs['dynamic_score_cluster'] = np.where(dynamic_score > .5, , 0)\n",
    "sns.displot(dynamic_score)\n",
    "plt.xlabel('dynamic score (normalized)')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# contributions per newly added kernel\n",
    "rcParams['figure.figsize'] = 5, 5\n",
    "rcParams['figure.dpi'] = 120\n",
    "sc.pl.umap(ad, color=['dynamic_score'], cmap='RdBu_r', sort_order=True)\n",
    "sc.pl.umap(ad, color=['dynamic_score_z1'], cmap='RdBu_r', sort_order=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sc.tl.embedding_density(ad, basis='umap', groupby='dynamic_score_z1')\n",
    "sc.pl.embedding_density(ad, basis='umap', key='umap_density_dynamic_score_z1', group='dynamic') # basis='umap', groupby='dynamic_score_cluster')\n",
    "sc.tl.embedding_density(ad, basis='umap', groupby='dynamic_score_z2')\n",
    "sc.pl.embedding_density(ad, basis='umap', key='umap_density_dynamic_score_z2', group='dynamic') # basis='umap', groupby='dynamic_score_cluster')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mb.pl.set_rcParams({'figure.figsize': [5, 5], 'figure.dpi': 90})\n",
    "mb.pl.kmer_enrichment(model, train, log_scale=False, style='scatter', ylab='t1', xlab='p1', k=6)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "conda-env-mubind-py",
   "language": "python",
   "display_name": "Python [conda env:mubind]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}