{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b35c08e6-e4ee-48f3-bd31-d975d8a71582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import multibind as mb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as tnn\n",
    "import torch.optim as topti\n",
    "import torch.utils.data as tdata\n",
    "import bindome as bd\n",
    "bd.constants.ANNOTATIONS_DIRECTORY = '../annotations'\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import logomaker\n",
    "import os\n",
    "import scipy\n",
    "import pickle\n",
    "\n",
    "# Use a GPU if available, as it should be faster.\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device: \" + str(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e2eebad-ed0d-4ece-9b71-97493739f1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "matlab_path = os.path.join(bd.constants.ANNOTATIONS_DIRECTORY, 'pbm', 'affreg', 'PbmDataHom6_norm.mat')\n",
    "mat = scipy.io.loadmat(matlab_path)\n",
    "data = mat['PbmData'][0]\n",
    "seqs_dna =  data[0][5]\n",
    "seqs_dna = [s[0][0] for s in seqs_dna]\n",
    "# load the MSA sequences, one hot encoded\n",
    "df, signal = bd.datasets.PBM.pbm_homeo_affreg()\n",
    "# x, y = pickle.load(open('../../data/example_homeo_PbmData.pkl', 'rb'))\n",
    "x, y = pickle.load(open('../annotations/pbm/example_homeo_PbmData.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c40781d-1ed3-47ed-a509-2a2765b2dc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_input = np.stack(x).transpose((0, 2, 1)).astype(np.float32)\n",
    "x_input = torch.Tensor(x_input)\n",
    "\n",
    "x_target = torch.Tensor(np.stack(x).astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b2ea2853-ccc0-46c3-b926-0d493aa183af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(tnn.Module):\n",
    "    def __init__(self, input_size=21, seq_length=88):\n",
    "        super().__init__()\n",
    "        self.encoder = mb.models.BMPrediction(num_classes=1, input_size=input_size, hidden_size=2, num_layers=1, seq_length=seq_length)\n",
    "        self.decoder = mb.models.Decoder(enc_size=input_size, seq_length=seq_length)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e3112d4-f664-40b5-a973-d411b70a976f",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Autoencoder()\n",
    "criterion = tnn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(autoencoder.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 1001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "48b77861-0ead-472b-be7b-99d9e4ce13ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(autoencoder, num_epochs, x_input, x_target, criterion, optimizer):\n",
    "    for epoch in range(num_epochs):\n",
    "        outputs = autoencoder(x_input) #forward pass\n",
    "        # print(outputs.shape)\n",
    "        optimizer.zero_grad() #caluclate the gradient, manually setting to 0\n",
    "\n",
    "        # obtain the loss function\n",
    "        loss = criterion(outputs, x_target)\n",
    "\n",
    "        loss.backward() #calculates the loss of the loss function\n",
    "\n",
    "        optimizer.step() #improve from loss, i.e backprop\n",
    "        if epoch % 200 == 0:\n",
    "            print(\"Epoch: %d, loss: %1.5f\" % (epoch, loss.item())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "514ec511-391a-4d5e-bd4e-ec033165f16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(x_input, x_target, k=5):\n",
    "    val_losses = []\n",
    "    for i in range(k):\n",
    "        indices = np.array([j % k == i for j in range(x_input.shape[0])])\n",
    "        x_input_train = x_input[~indices]\n",
    "        x_input_test = x_input[indices]\n",
    "        x_target_train = x_target[~indices]\n",
    "        x_target_test = x_target[indices]\n",
    "        \n",
    "        autoencoder = Autoencoder(input_size=20, seq_length=50) #numbers should also be parameters\n",
    "        criterion = tnn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(autoencoder.parameters(), lr=0.001)\n",
    "        \n",
    "        train(autoencoder, num_epochs, x_input_train, x_target_train, criterion, optimizer)\n",
    "        \n",
    "        pred = autoencoder(x_input_test)\n",
    "        print(criterion(pred, x_target_test).item())\n",
    "        val_losses += [criterion(pred, x_target_test).item()]\n",
    "    return val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bdd8d369-c47e-4eed-85df-81095566818d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 3.04454\n",
      "Epoch: 200, loss: 0.60014\n",
      "Epoch: 400, loss: 0.18317\n",
      "Epoch: 600, loss: 0.09386\n",
      "Epoch: 800, loss: 0.05768\n",
      "Epoch: 1000, loss: 0.04241\n",
      "11.242741584777832\n",
      "Epoch: 0, loss: 3.04690\n",
      "Epoch: 200, loss: 0.86632\n",
      "Epoch: 400, loss: 0.76319\n",
      "Epoch: 600, loss: 0.74991\n",
      "Epoch: 800, loss: 0.74856\n",
      "Epoch: 1000, loss: 0.74821\n",
      "1.8671122789382935\n",
      "Epoch: 0, loss: 3.04582\n",
      "Epoch: 200, loss: 1.00713\n",
      "Epoch: 400, loss: 1.00712\n",
      "Epoch: 600, loss: 1.00712\n",
      "Epoch: 800, loss: 1.00712\n",
      "Epoch: 1000, loss: 1.00712\n",
      "1.057201862335205\n",
      "Epoch: 0, loss: 3.04357\n",
      "Epoch: 200, loss: 0.75241\n",
      "Epoch: 400, loss: 0.41967\n",
      "Epoch: 600, loss: 0.25304\n",
      "Epoch: 800, loss: 0.17557\n",
      "Epoch: 1000, loss: 0.12737\n",
      "5.542008876800537\n",
      "Epoch: 0, loss: 3.04773\n",
      "Epoch: 200, loss: 0.79510\n",
      "Epoch: 400, loss: 0.52657\n",
      "Epoch: 600, loss: 0.44165\n",
      "Epoch: 800, loss: 0.37785\n",
      "Epoch: 1000, loss: 0.34121\n",
      "3.3183066844940186\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2252716-100e-48ac-82e9-70846c72c240",
   "metadata": {},
   "source": [
    "# Cross-validation with simulated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "eba36a2d-6db4-46d2-85fe-d29d5bf41c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_seqs = 999\n",
    "n_aa = 50\n",
    "\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "from matplotlib import rcParams\n",
    "figsize = [5, 1]\n",
    "random.seed(42)\n",
    "aa_options = 'ACDEFGHIKLMNPQRSTVWY'\n",
    "seq_arr = np.array(list(aa_options))\n",
    "ref_seq = random.choices(sorted(seq_arr), k=n_aa)\n",
    "ref_seq = ''.join(ref_seq)\n",
    "\n",
    "import pandas as pd\n",
    "import logomaker\n",
    "np.random.seed(42)\n",
    "ref_w = pd.DataFrame(np.random.random((4, 10)), index=['A', 'C', 'G', 'T'])\n",
    "# logomaker.Logo(ref_w.T, shade_below=0.5, fade_below=0.5, figsize=figsize)\n",
    "# plt.show()\n",
    "# generate a random seq logo\n",
    "\n",
    "final_seqs = []\n",
    "final_w = []\n",
    "curr_seq = ref_seq\n",
    "curr_w = ref_w\n",
    "final_seqs.append(curr_seq)\n",
    "final_w.append(ref_w)\n",
    "\n",
    "n_mutate = 2\n",
    "for i in range(n_seqs):\n",
    "    new_seq = curr_seq\n",
    "    for mut_i in range(n_mutate):\n",
    "        # mutate the protein sequence\n",
    "        pi = np.random.randint(0, len(curr_seq))\n",
    "        new_aa = aa_options[np.random.randint(0, len(aa_options))]\n",
    "        # print(pi, new_aa)    \n",
    "\n",
    "        new_seq = curr_seq[:pi] + new_aa + curr_seq[pi + 1:]\n",
    "        # print(new_seq)\n",
    "\n",
    "    final_seqs.append(new_seq)\n",
    "    curr_seq = new_seq\n",
    "    \n",
    "    # mutate PWMs at one position\n",
    "    pw = np.random.randint(0, ref_w.shape[1])\n",
    "    new_w = pd.concat([curr_w.iloc[:,:pw],\n",
    "                       pd.DataFrame(np.random.random((4, 1)), index=['A', 'C', 'G', 'T']),\n",
    "                       curr_w.iloc[:,pw+1:]],\n",
    "                     axis=1)\n",
    "    new_w.columns = range(new_w.shape[1])\n",
    "    # print(new_w)\n",
    "    # logomaker.Logo(new_w.T, shade_below=0.5, fade_below=0.5, figsize=figsize)\n",
    "    # plt.show()\n",
    "    final_w.append(new_w)\n",
    "    curr_w = new_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d08c6118-aaec-4fd0-9c15-6eff664c567c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "def onehot_aa(seq, label_encoder=LabelEncoder(), onehot_encoder=OneHotEncoder(sparse=False)):\n",
    "    seq_arr = np.array(list(seq + \"ACDEFGHIKLMNPQRSTVWY\"))\n",
    "    seq_int = label_encoder.fit_transform(seq_arr)\n",
    "    pre_onehot = onehot_encoder.fit_transform(seq_int.reshape(-1, 1))\n",
    "    return (\n",
    "        pre_onehot.T[:, :-20]\n",
    "    ).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b7e393ab-812a-4d37-a7fb-0641b2c896de",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_seq = len(final_seqs)\n",
    "single_seq = \"\".join(final_seqs)\n",
    "onehot = np.array(onehot_aa(single_seq))\n",
    "onehot = np.array(np.split(onehot, n_seq, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "47cc2206-69fa-4153-a665-37cf4582e420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 20, 50)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ed5d4bea-aab3-41a8-ac44-fa71baf527f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_input = torch.Tensor(onehot.transpose((0, 2, 1)).astype(np.float32))\n",
    "\n",
    "x_target = torch.Tensor(onehot.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "bef57ea0-9d4e-4d1c-98f9-bf7f9e0944d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 2.99554\n",
      "Epoch: 200, loss: 0.97880\n",
      "Epoch: 400, loss: 0.45276\n",
      "Epoch: 600, loss: 0.31102\n",
      "Epoch: 800, loss: 0.26616\n",
      "Epoch: 1000, loss: 0.22280\n",
      "0.3763960599899292\n",
      "Epoch: 0, loss: 2.99603\n",
      "Epoch: 200, loss: 0.54630\n",
      "Epoch: 400, loss: 0.34404\n",
      "Epoch: 600, loss: 0.28986\n",
      "Epoch: 800, loss: 0.24101\n",
      "Epoch: 1000, loss: 0.21185\n",
      "0.36328426003456116\n",
      "Epoch: 0, loss: 2.99520\n",
      "Epoch: 200, loss: 1.34428\n",
      "Epoch: 400, loss: 0.89640\n",
      "Epoch: 600, loss: 0.69996\n",
      "Epoch: 800, loss: 0.56334\n",
      "Epoch: 1000, loss: 0.50843\n",
      "0.5557398200035095\n",
      "Epoch: 0, loss: 2.99512\n",
      "Epoch: 200, loss: 0.93819\n",
      "Epoch: 400, loss: 0.67549\n",
      "Epoch: 600, loss: 0.57986\n",
      "Epoch: 800, loss: 0.54387\n",
      "Epoch: 1000, loss: 0.52006\n",
      "0.8059558868408203\n",
      "Epoch: 0, loss: 2.99606\n",
      "Epoch: 200, loss: 1.22230\n",
      "Epoch: 400, loss: 0.77524\n",
      "Epoch: 600, loss: 0.64947\n",
      "Epoch: 800, loss: 0.53295\n",
      "Epoch: 1000, loss: 0.44251\n",
      "0.6242820024490356\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_losses = cross_validation(x_input, x_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2d41e376-004c-4197-a87f-42b71719bfc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3763960599899292,\n",
       " 0.36328426003456116,\n",
       " 0.5557398200035095,\n",
       " 0.8059558868408203,\n",
       " 0.6242820024490356]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_losses"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (multibind)",
   "language": "python",
   "name": "multibind"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
