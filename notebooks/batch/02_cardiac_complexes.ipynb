{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/ignacio.ibarra/Dropbox/workspace/theislab/mubind/notebooks/batch\n"
     ]
    }
   ],
   "source": [
    "cd workspace/theislab/mubind/notebooks/batch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rio/miniconda3/envs/mubind/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import mubind as mb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import bindome as bd\n",
    "bd.constants.ANNOTATIONS_DIRECTORY = '../../annotations'\n",
    "# mb.models.MultiBind\n",
    "import torch.optim as topti\n",
    "import torch.utils.data as tdata\n",
    "import matplotlib.pyplot as plt\n",
    "import logomaker\n",
    "\n",
    "# Use a GPU if available, as it should be faster.\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device: \" + str(device))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GATA4-ZeroCycle_0_R46777-R46777_10000000.tsv.gz (6092172, 6)\n",
      "(5000, 7)\n",
      "GATA4TBX5-ZeroCycle_0_R46999-R46999_10000000.tsv.gz (6708536, 6)\n",
      "(5000, 7)\n",
      "NKX2-5-ZeroCycle_0_R46777-R46777_10000000.tsv.gz (6193797, 6)\n",
      "(5000, 7)\n",
      "NKX2-5GATA4-ZeroCycle_0_R46777-R46777_10000000.tsv.gz (5707797, 6)\n",
      "(5000, 7)\n",
      "NKX2-5TBX5-ZeroCycle_0_R46888-R46888_10000000.tsv.gz (7349709, 6)\n",
      "(5000, 7)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "n_sample = 5000\n",
    "df = []\n",
    "basedir = '../../../mubind-pipeline/output/snakemake/SELEX'\n",
    "batch = 0\n",
    "for tf in os.listdir(basedir):\n",
    "    for f in os.listdir(os.path.join(basedir, tf)):\n",
    "        if f.endswith('.tsv.gz'):\n",
    "            df2 = pd.read_csv(os.path.join(basedir, tf, f), sep='\\t', index_col=0) # .head(100)\n",
    "            print(f, df2.shape)\n",
    "            assert 'batch' in df2\n",
    "            # print(df2.columns)\n",
    "            # df2 = df2.sample(100000)\n",
    "            n_rounds = len(df2.columns) - 2\n",
    "            df2.columns =  list(range(n_rounds)) + ['batch', 'is_count_data']\n",
    "            df2['batch'] = batch\n",
    "            df2['n_rounds'] = n_rounds\n",
    "            # df2 = mb.pp.sample_rounds(df2, n_rounds, n_sample_per_round)\n",
    "            df2 = df2.sample(n_sample)\n",
    "            print(df2.shape)\n",
    "            batch += 1\n",
    "            df.append(df2)\n",
    "            # assert False\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# concatenation/reordering\n",
    "df = pd.concat(df)\n",
    "df = df[[c for c in df.columns if not c in ['batch', 'is_count_data', 'n_rounds']] + ['batch', 'is_count_data', 'n_rounds']]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "(25000, 7)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 7)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "dataset = mb.datasets.SelexDataset(df, n_rounds=df['n_rounds'], labels=list(df.columns[:-3]))\n",
    "train = tdata.DataLoader(dataset=dataset,\n",
    "                         batch_size=1024,\n",
    "                         # batch_size=512,\n",
    "                         shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "%load_ext line_profiler\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "80"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total entries (25000, 4)\n"
     ]
    }
   ],
   "source": [
    "print('total entries', dataset.rounds.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.expand_frame_repr', False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "##NEW JOB\n",
      "ignore kernel 1\n",
      "next w 15 <class 'int'>\n",
      "# rounds {4}\n",
      "# rounds {4}\n",
      "# use_mono True\n",
      "# use_dinuc True\n",
      "# batches 5\n",
      "# kernels 5\n",
      "# initial w 15\n",
      "# enr_series True\n",
      "\n",
      "Kernel to optimize 0\n",
      "\n",
      "FREEZING KERNELS\n",
      "optimizing feature type mono\n",
      "setting grad status of kernel (mono, dinuc) at 0 to (1, 0)\n",
      "setting grad status of kernel (mono, dinuc) at 1 to (0, 0)\n",
      "setting grad status of kernel (mono, dinuc) at 2 to (0, 0)\n",
      "setting grad status of kernel (mono, dinuc) at 3 to (0, 0)\n",
      "setting grad status of kernel (mono, dinuc) at 4 to (0, 0)\n",
      "\n",
      "\n",
      "kernels mask [0 1 1 1 1]\n",
      "optimizer:  <class 'torch.optim.adam.Adam'> \n",
      "criterion: <class 'mubind.tl.loss.PoissonLoss'> \n",
      "# epochs: 450 \n",
      "early_stopping: 5\n",
      "lr= 0.05, weight_decay= 0.05, dir weight= 0\n",
      "Epoch: 26, Loss: 2.370995 , best epoch: 24 secs per epoch: 0.450 s\n",
      "Epoch: 51, Loss: 2.370834 , best epoch: 49 secs per epoch: 0.432 s\n",
      "Epoch: 76, Loss: 2.370784 , best epoch: 74 secs per epoch: 0.425 s\n",
      "Epoch: 101, Loss: 2.370763 , best epoch: 99 secs per epoch: 0.424 s\n",
      "Epoch: 126, Loss: 2.370753 , best epoch: 124 secs per epoch: 0.451 s\n",
      "Epoch: 151, Loss: 2.370747 , best epoch: 149 secs per epoch: 0.443 s\n",
      "Epoch: 176, Loss: 2.370745 , best epoch: 174 secs per epoch: 0.440 s\n",
      "Epoch: 201, Loss: 2.370743 , best epoch: 199 secs per epoch: 0.440 s\n",
      "Epoch: 226, Loss: 2.370742 , best epoch: 223 secs per epoch: 0.439 s\n",
      "Epoch: 251, Loss: 2.370742 , best epoch: 249 secs per epoch: 0.440 s\n",
      "Epoch: 267, Loss: 2.3707 , best epoch: 261 secs per epoch: 0.441 s\n",
      "early stop!\n",
      "Final loss: 2.3707419491\n",
      "Total time (model/function): (117.418s / 117.418s)\n",
      "Time per epoch (model/function): (0.441s/ 0.441s)\n",
      "Time per epoch per 1k trials: 0.018s\n",
      "Current time: 2022-12-25 11:58:11.746222\n",
      "optimization of dinuc is not necessary for the intercepts (kernel=0). Skip...\n",
      "\n",
      "Kernel to optimize 1\n",
      "\n",
      "FREEZING KERNELS\n",
      "optimizing feature type mono\n",
      "setting grad status of kernel (mono, dinuc) at 0 to (0, 0)\n",
      "setting grad status of kernel (mono, dinuc) at 1 to (1, 0)\n",
      "setting grad status of kernel (mono, dinuc) at 2 to (0, 0)\n",
      "setting grad status of kernel (mono, dinuc) at 3 to (0, 0)\n",
      "setting grad status of kernel (mono, dinuc) at 4 to (0, 0)\n",
      "\n",
      "\n",
      "kernels mask [0 0 1 1 1]\n",
      "optimizer:  <class 'torch.optim.adam.Adam'> \n",
      "criterion: <class 'mubind.tl.loss.PoissonLoss'> \n",
      "# epochs: 450 \n",
      "early_stopping: 25\n",
      "lr= 0.05, weight_decay= 0.005, dir weight= 0\n",
      "Epoch: 26, Loss: 0.950792 , best epoch: 24 secs per epoch: 0.503 s\n",
      "Epoch: 51, Loss: 0.948264 , best epoch: 41 secs per epoch: 0.494 s\n",
      "Epoch: 67, Loss: 0.9485 , best epoch: 41 secs per epoch: 0.506 s\n",
      "early stop!\n",
      "Final loss: 0.9484858489\n",
      "Total time (model/function): (150.847s / 33.429s)\n",
      "Time per epoch (model/function): (2.286s/ 0.506s)\n",
      "Time per epoch per 1k trials: 0.020s\n",
      "Current time: 2022-12-25 11:58:45.178344\n",
      "\n",
      "WIDTH OPTIMIZATION (first)...\n",
      "options to try [[0, 0, 0], [0, 1, 0], [0, 2, 0], [1, 0, 0], [1, 1, 0], [1, 2, 0], [2, 0, 0], [2, 1, 0], [2, 2, 0]]\n",
      "next expand left: 0, next expand right: 0, shift: 0\n",
      "optimizer:  <class 'torch.optim.adam.Adam'> \n",
      "criterion: <class 'mubind.tl.loss.PoissonLoss'> \n",
      "# epochs: 450 \n",
      "early_stopping: 25\n",
      "lr= 0.05, weight_decay= 0.005, dir weight= 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [16], line 31\u001B[0m\n\u001B[1;32m     29\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m##NEW JOB\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     30\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mignore kernel\u001B[39m\u001B[38;5;124m'\u001B[39m, ignore_kernel)\n\u001B[0;32m---> 31\u001B[0m     model_by_k, res_next \u001B[38;5;241m=\u001B[39m \u001B[43mmb\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtl\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptimize_iterative\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mw\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mw\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshow_logo\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     32\u001B[0m \u001B[43m                                                 \u001B[49m\u001B[43mopt_kernel_shift\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mopt_kernel_shift\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mopt_kernel_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mopt_kernel_length\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     33\u001B[0m \u001B[43m                                                 \u001B[49m\u001B[43mdirichlet_regularization\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdirichlet_regularization\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;66;43;03m# 10 ** dirichlet_regularization_log,\u001B[39;49;00m\n\u001B[1;32m     34\u001B[0m \u001B[43m                                                 \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwd\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mignore_kernel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mignore_kernel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muse_mono\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     35\u001B[0m \u001B[43m                                                 \u001B[49m\u001B[43mnum_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_epochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mearly_stopping\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mearly_stopping\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muse_dinuc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;66;43;03m# optimiser=torch.optim.LBFGS,\u001B[39;49;00m\n\u001B[1;32m     36\u001B[0m \u001B[43m                                                 \u001B[49m\u001B[43mn_kernels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_kernels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlog_each\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlog_each\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop_at_kernel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m \u001B[38;5;66;03m#  seed=seed) # seeds.index[0]) #\u001B[39;00m\n\u001B[1;32m     37\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m##DONE....\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     40\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtotal time: \u001B[39m\u001B[38;5;132;01m%.3f\u001B[39;00m\u001B[38;5;124m s\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m%\u001B[39m ((time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m t0)))\n",
      "File \u001B[0;32m/mnt/c/Users/ignacio.ibarra/Dropbox/workspace/theislab/mubind/mubind/tl/prediction.py:506\u001B[0m, in \u001B[0;36moptimize_iterative\u001B[0;34m(train, device, n_kernels, w, max_w, num_epochs, early_stopping, log_each, opt_kernel_shift, opt_kernel_length, expand_length_max, expand_length_step, show_logo, optimiser, criterion, seed, init_random, joint_learning, ignore_kernel, lr, weight_decay, stop_at_kernel, dirichlet_regularization, verbose, exp_max, shift_max, shift_step, use_mono, use_dinuc, r2_per_epoch, **kwargs)\u001B[0m\n\u001B[1;32m    501\u001B[0m \u001B[38;5;66;03m# print(model_by_k[k_parms].loss_color)\u001B[39;00m\n\u001B[1;32m    502\u001B[0m \u001B[38;5;66;03m#######\u001B[39;00m\n\u001B[1;32m    503\u001B[0m \u001B[38;5;66;03m# optimize the flanks through +1/-1 shifts\u001B[39;00m\n\u001B[1;32m    504\u001B[0m \u001B[38;5;66;03m#######\u001B[39;00m\n\u001B[1;32m    505\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (opt_kernel_shift \u001B[38;5;129;01mor\u001B[39;00m opt_kernel_length) \u001B[38;5;129;01mand\u001B[39;00m i \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m--> 506\u001B[0m     model \u001B[38;5;241m=\u001B[39m \u001B[43moptimize_width_and_length\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    507\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    508\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    509\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43mexpand_length_max\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    510\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43mexpand_length_step\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    511\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43mshift_max\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    512\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43mshift_step\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    513\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    514\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43mfeat_i\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfeat_i\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    515\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43mcolors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcolors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    516\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    517\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnext_lr\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    518\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnext_weight_decay\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    519\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43moptimiser\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptimiser\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    520\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43mlog_each\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlog_each\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    521\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43mexp_max\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mexp_max\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    522\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43mdirichlet_regularization\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdirichlet_regularization\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    523\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43mearly_stopping\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnext_early_stopping\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    524\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43mshow_logo\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mshow_logo\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    525\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43mn_kernels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_kernels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    526\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43mw\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mw\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    527\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43mmax_w\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_w\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    528\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43mnum_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_epochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    529\u001B[0m \u001B[43m                                      \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    531\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m show_logo:\n\u001B[1;32m    532\u001B[0m     vprint(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mafter shift optimz model\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m/mnt/c/Users/ignacio.ibarra/Dropbox/workspace/theislab/mubind/mubind/tl/prediction.py:673\u001B[0m, in \u001B[0;36moptimize_width_and_length\u001B[0;34m(train, model, device, expand_length_max, expand_length_step, shift_max, shift_step, i, colors, verbose, lr, weight_decay, optimiser, log_each, exp_max, num_epochs_shift_factor, dirichlet_regularization, early_stopping, criterion, show_logo, feat_i, n_kernels, w, max_w, num_epochs, loss_thr_pct, **kwargs)\u001B[0m\n\u001B[1;32m    670\u001B[0m model_shift\u001B[38;5;241m.\u001B[39mr2_history \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m    671\u001B[0m model_shift\u001B[38;5;241m.\u001B[39mloss_color \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m--> 673\u001B[0m \u001B[43mmb\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtl\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptimize_modified_kernel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    674\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel_shift\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    675\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    676\u001B[0m \u001B[43m    \u001B[49m\u001B[43mkernel_i\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    677\u001B[0m \u001B[43m    \u001B[49m\u001B[43mshift\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mshift\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    678\u001B[0m \u001B[43m    \u001B[49m\u001B[43mexpand_left\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mexpand_left\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    679\u001B[0m \u001B[43m    \u001B[49m\u001B[43mexpand_right\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mexpand_right\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    680\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    681\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnum_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_epochs\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mopt_option_text\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mWIDTH\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mnum_epochs\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mnum_epochs_shift_factor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    682\u001B[0m \u001B[43m    \u001B[49m\u001B[43mearly_stopping\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mearly_stopping\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    683\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlog_each\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_epochs\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mopt_option_text\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mWIDTH\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mnum_epochs\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mnum_epochs_shift_factor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;66;43;03m# log_each,\u001B[39;49;00m\n\u001B[1;32m    684\u001B[0m \u001B[43m    \u001B[49m\u001B[43mupdate_grad_i\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    685\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfeat_i\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfeat_i\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    686\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlr\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    687\u001B[0m \u001B[43m    \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mweight_decay\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    688\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptimiser\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptimiser\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    689\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    690\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdirichlet_regularization\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdirichlet_regularization\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    691\u001B[0m \u001B[43m    \u001B[49m\u001B[43mexp_max\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mexp_max\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    692\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    693\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    694\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    695\u001B[0m vprint(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    697\u001B[0m model_shift\u001B[38;5;241m.\u001B[39mloss_color \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(np\u001B[38;5;241m.\u001B[39mrepeat(next_color, \u001B[38;5;28mlen\u001B[39m(model_shift\u001B[38;5;241m.\u001B[39mloss_history)))\n",
      "File \u001B[0;32m/mnt/c/Users/ignacio.ibarra/Dropbox/workspace/theislab/mubind/mubind/tl/prediction.py:798\u001B[0m, in \u001B[0;36moptimize_modified_kernel\u001B[0;34m(model, train, shift, expand_left, expand_right, device, num_epochs, early_stopping, log_each, feat_i, update_grad_i, use_dinuc, kernel_i, lr, weight_decay, optimiser, criterion, dirichlet_regularization, exp_max, verbose, **kwargs)\u001B[0m\n\u001B[1;32m    795\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m criterion \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    796\u001B[0m     criterion \u001B[38;5;241m=\u001B[39m mb\u001B[38;5;241m.\u001B[39mtl\u001B[38;5;241m.\u001B[39mPoissonLoss()\n\u001B[0;32m--> 798\u001B[0m \u001B[43moptimize_simple\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    799\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    800\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    801\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    802\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptimiser\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    803\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    804\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnum_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_epochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    805\u001B[0m \u001B[43m    \u001B[49m\u001B[43mearly_stopping\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mearly_stopping\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    806\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlog_each\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlog_each\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    807\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdirichlet_regularization\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdirichlet_regularization\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    808\u001B[0m \u001B[43m    \u001B[49m\u001B[43mexp_max\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mexp_max\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    809\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    810\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    812\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m model\n",
      "File \u001B[0;32m/mnt/c/Users/ignacio.ibarra/Dropbox/workspace/theislab/mubind/mubind/tl/prediction.py:200\u001B[0m, in \u001B[0;36moptimize_simple\u001B[0;34m(model, dataloader, device, optimiser, criterion, num_epochs, early_stopping, dirichlet_regularization, exp_max, log_each, verbose, r2_per_epoch)\u001B[0m\n\u001B[1;32m    198\u001B[0m \u001B[38;5;66;03m# loss = criterion(outputs, rounds) + 0.01*reconstruct_crit(reconstruction, residues) + dir_weight\u001B[39;00m\n\u001B[1;32m    199\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m exp_max \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m--> 200\u001B[0m     loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexp_barrier\u001B[49m\u001B[43m(\u001B[49m\u001B[43mexp_max\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    201\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()  \u001B[38;5;66;03m# Calculate gradients.\u001B[39;00m\n\u001B[1;32m    202\u001B[0m optimiser\u001B[38;5;241m.\u001B[39mstep()\n",
      "File \u001B[0;32m/mnt/c/Users/ignacio.ibarra/Dropbox/workspace/theislab/mubind/mubind/models/models.py:169\u001B[0m, in \u001B[0;36mMultibind.exp_barrier\u001B[0;34m(self, exp_max)\u001B[0m\n\u001B[1;32m    167\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m    168\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparameters():\n\u001B[0;32m--> 169\u001B[0m     out \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39msum(torch\u001B[38;5;241m.\u001B[39mexp(p \u001B[38;5;241m-\u001B[39m exp_max) \u001B[38;5;241m+\u001B[39m torch\u001B[38;5;241m.\u001B[39mexp(\u001B[38;5;241m-\u001B[39mp \u001B[38;5;241m-\u001B[39m exp_max))\n\u001B[1;32m    170\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m out\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# assign batch and data type\n",
    "\n",
    "# data['batch'] = 0\n",
    "# data['is_count_data'] = 1\n",
    "# n_batches=3\n",
    "\n",
    "dirichlet_regularization = 0\n",
    "# for dirichlet_regularization_log in range(-5, 3):\n",
    "\n",
    "n_epochs = 450\n",
    "log_each = 25\n",
    "n_kernels = 5\n",
    "lr = [0.05] * n_kernels\n",
    "wd = [0.05,] + [0.005] * (n_kernels - 1)\n",
    "early_stopping = [5,] + [25] * (n_kernels - 1)\n",
    "w = 15 # min(len(motif), 6)\n",
    "opt_kernel_shift = 1\n",
    "opt_kernel_length = 1\n",
    "\n",
    "from matplotlib import rcParams\n",
    "rcParams['figure.figsize'] = 8, 1\n",
    "\n",
    "import time\n",
    "t0 = time.time()\n",
    "\n",
    "criterion = mb.tl.PoissonLoss()\n",
    "\n",
    "for ignore_kernel in [1]: # [0, 1]:\n",
    "    print('\\n\\n##NEW JOB')\n",
    "    print('ignore kernel', ignore_kernel)\n",
    "    model_by_k, res_next = mb.tl.optimize_iterative(train, device, w=w, show_logo=0, criterion=criterion,\n",
    "                                                 opt_kernel_shift=opt_kernel_shift, opt_kernel_length=opt_kernel_length,\n",
    "                                                 dirichlet_regularization=dirichlet_regularization, # 10 ** dirichlet_regularization_log,\n",
    "                                                 lr=lr, weight_decay=wd, ignore_kernel=ignore_kernel, use_mono=True,\n",
    "                                                 num_epochs=n_epochs, early_stopping=early_stopping, use_dinuc=True, # optimiser=torch.optim.LBFGS,\n",
    "                                                 n_kernels=n_kernels, log_each=log_each, stop_at_kernel=None) #  seed=seed) # seeds.index[0]) #\n",
    "    print('##DONE....\\n\\n')\n",
    "\n",
    "\n",
    "print('total time: %.3f s' % ((time.time() - t0)))\n",
    "# res = []\n",
    "# model_by_k = {}\n",
    "\n",
    "model = model_by_k\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### We can visualize the overall results obtained by the network, once the training is finished"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# %load_ext line_profiler\n",
    "# %lprun -f mb.tl.optimize_simple mb.tl.optimize_iterative(train, device, w=w, show_logo=0, criterion=criterion, opt_kernel_shift=0, opt_kernel_length=0, dirichlet_regularization=dirichlet_regularization, lr=lr, weight_decay=wd, ignore_kernel=ignore_kernel, num_epochs=n_epochs, early_stopping=early_stopping, use_dinuc=False, n_kernels=n_kernels, log_each=log_each, stop_at_kernel=None) #  seed=seed) # seeds.index[0]) #\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import mubind as mb"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = model_by_k\n",
    "mb.tl.scores(model, train)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "counts = mb.tl.predict(model, train)\n",
    "counts"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "weight_mono_i = model.binding_modes.conv_mono[1].weight\n",
    "pos_w_sum = weight_mono_i[weight_mono_i > 0].sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "weight_mono_i[weight_mono_i > 0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 5, 5\n",
    "mb.pl.kmer_enrichment(model, train, log_scale=False, style='scatter', ylab='t1', xlab='p1', k=5)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mb.pl.conv(model)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "mubind",
   "language": "python",
   "display_name": "mubind"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}