{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'workspace/theislab/mubind/notebooks/batch'\n",
      "/mnt/c/Users/ignacio.ibarra/Dropbox/workspace/theislab/mubind/notebooks/batch\n"
     ]
    }
   ],
   "source": [
    "cd workspace/theislab/mubind/notebooks/batch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import mubind as mb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import bindome as bd\n",
    "bd.constants.ANNOTATIONS_DIRECTORY = '../../annotations'\n",
    "# mb.models.MultiBind\n",
    "import torch.optim as topti\n",
    "import torch.utils.data as tdata\n",
    "import matplotlib.pyplot as plt\n",
    "import logomaker\n",
    "\n",
    "# Use a GPU if available, as it should be faster.\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device: \" + str(device))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALX1-ZeroCycle_TACCAA40NTTA_0_0-TACCAA40NTTA_10000.tsv.gz (10000, 7)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot take a larger sample than population when 'replace=False'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [100], line 20\u001B[0m\n\u001B[1;32m     18\u001B[0m df2[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mn_rounds\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m n_rounds\n\u001B[1;32m     19\u001B[0m \u001B[38;5;66;03m# df2 = mb.pp.sample_rounds(df2, n_rounds, n_sample_per_round)\u001B[39;00m\n\u001B[0;32m---> 20\u001B[0m df2 \u001B[38;5;241m=\u001B[39m \u001B[43mdf2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msample\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn_sample\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;28mprint\u001B[39m(df2\u001B[38;5;241m.\u001B[39mshape)\n\u001B[1;32m     22\u001B[0m batch \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[0;32m~/miniconda3/envs/mubind/lib/python3.10/site-packages/pandas/core/generic.py:5773\u001B[0m, in \u001B[0;36mNDFrame.sample\u001B[0;34m(self, n, frac, replace, weights, random_state, axis, ignore_index)\u001B[0m\n\u001B[1;32m   5770\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m weights \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   5771\u001B[0m     weights \u001B[38;5;241m=\u001B[39m sample\u001B[38;5;241m.\u001B[39mpreprocess_weights(\u001B[38;5;28mself\u001B[39m, weights, axis)\n\u001B[0;32m-> 5773\u001B[0m sampled_indices \u001B[38;5;241m=\u001B[39m \u001B[43msample\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msample\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj_len\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msize\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreplace\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweights\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   5774\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtake(sampled_indices, axis\u001B[38;5;241m=\u001B[39maxis)\n\u001B[1;32m   5776\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ignore_index:\n",
      "File \u001B[0;32m~/miniconda3/envs/mubind/lib/python3.10/site-packages/pandas/core/sample.py:150\u001B[0m, in \u001B[0;36msample\u001B[0;34m(obj_len, size, replace, weights, random_state)\u001B[0m\n\u001B[1;32m    147\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    148\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInvalid weights: weights sum to zero\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 150\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mrandom_state\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mchoice\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj_len\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msize\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreplace\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreplace\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mp\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mweights\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mastype(\n\u001B[1;32m    151\u001B[0m     np\u001B[38;5;241m.\u001B[39mintp, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m    152\u001B[0m )\n",
      "File \u001B[0;32mmtrand.pyx:965\u001B[0m, in \u001B[0;36mnumpy.random.mtrand.RandomState.choice\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: Cannot take a larger sample than population when 'replace=False'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "n_sample = 25000\n",
    "df = []\n",
    "basedir = '../../../mubind-pipeline/output/snakemake/SELEX'\n",
    "batch = 0\n",
    "for tf in os.listdir(basedir):\n",
    "    for f in os.listdir(os.path.join(basedir, tf)):\n",
    "        if f.endswith('.tsv.gz'):\n",
    "            df2 = pd.read_csv(os.path.join(basedir, tf, f), sep='\\t', index_col=0) # .head(100)\n",
    "            print(f, df2.shape)\n",
    "            assert 'batch' in df2\n",
    "            # print(df2.columns)\n",
    "            # df2 = df2.sample(100000)\n",
    "            n_rounds = len(df2.columns) - 2\n",
    "            df2.columns =  list(range(n_rounds)) + ['batch', 'is_count_data']\n",
    "            df2['batch'] = batch\n",
    "            df2['n_rounds'] = n_rounds\n",
    "            # df2 = mb.pp.sample_rounds(df2, n_rounds, n_sample_per_round)\n",
    "            df2 = df2.sample(n_sample)\n",
    "            print(df2.shape)\n",
    "            batch += 1\n",
    "            df.append(df2)\n",
    "            # assert False\n",
    "            break\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# concatenation/reordering\n",
    "df = pd.concat(df[:1])\n",
    "df = df[[c for c in df.columns if not c in ['batch', 'is_count_data', 'n_rounds']] + ['batch', 'is_count_data', 'n_rounds']]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "dataset = mb.datasets.SelexDataset(df, n_rounds=df['n_rounds'], labels=list(df.columns[:-3]))\n",
    "train = tdata.DataLoader(dataset=dataset,\n",
    "                         batch_size=512,\n",
    "                         # batch_size=512,\n",
    "                         shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%load_ext line_profiler\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('total entries', dataset.rounds.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.expand_frame_repr', False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# assign batch and data type\n",
    "\n",
    "# data['batch'] = 0\n",
    "# data['is_count_data'] = 1\n",
    "# n_batches=3\n",
    "\n",
    "dirichlet_regularization = 0\n",
    "# for dirichlet_regularization_log in range(-5, 3):\n",
    "\n",
    "n_epochs = 450\n",
    "log_each = 25\n",
    "n_kernels = 2\n",
    "lr = [0.05] * n_kernels\n",
    "wd = [0.05,] + [0.005] * (n_kernels - 1)\n",
    "early_stopping = [5,] + [25] * (n_kernels - 1)\n",
    "w = 20 # min(len(motif), 6)\n",
    "opt_kernel_shift = 1\n",
    "opt_kernel_length = 1\n",
    "\n",
    "from matplotlib import rcParams\n",
    "rcParams['figure.figsize'] = 8, 1\n",
    "\n",
    "import time\n",
    "t0 = time.time()\n",
    "\n",
    "criterion = mb.tl.PoissonLoss()\n",
    "\n",
    "for ignore_kernel in [1]: # [0, 1]:\n",
    "    print('\\n\\n##NEW JOB')\n",
    "    print('ignore kernel', ignore_kernel)\n",
    "    model_by_k, res_next = mb.tl.optimize_iterative(train, device, w=w, show_logo=0, criterion=criterion,\n",
    "                                                 opt_kernel_shift=opt_kernel_shift, opt_kernel_length=opt_kernel_length,\n",
    "                                                 dirichlet_regularization=dirichlet_regularization, # 10 ** dirichlet_regularization_log,\n",
    "                                                 lr=lr, weight_decay=wd, ignore_kernel=ignore_kernel, use_mono=True,\n",
    "                                                 num_epochs=n_epochs, early_stopping=early_stopping, use_dinuc=True, # optimiser=torch.optim.LBFGS,\n",
    "                                                 n_kernels=n_kernels, log_each=log_each, stop_at_kernel=None) #  seed=seed) # seeds.index[0]) #\n",
    "    print('##DONE....\\n\\n')\n",
    "\n",
    "\n",
    "print('total time: %.3f s' % ((time.time() - t0)))\n",
    "# res = []\n",
    "# model_by_k = {}\n",
    "\n",
    "model = model_by_k\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### We can visualize the overall results obtained by the network, once the training is finished"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# %load_ext line_profiler\n",
    "# %lprun -f mb.tl.optimize_simple mb.tl.optimize_iterative(train, device, w=w, show_logo=0, criterion=criterion, opt_kernel_shift=0, opt_kernel_length=0, dirichlet_regularization=dirichlet_regularization, lr=lr, weight_decay=wd, ignore_kernel=ignore_kernel, num_epochs=n_epochs, early_stopping=early_stopping, use_dinuc=False, n_kernels=n_kernels, log_each=log_each, stop_at_kernel=None) #  seed=seed) # seeds.index[0]) #\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import mubind as mb"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = model_by_k\n",
    "mb.tl.scores(model, train, k=-1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "counts = mb.tl.predict(model, train)\n",
    "counts"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "weight_mono_i = model.binding_modes.conv_mono[1].weight\n",
    "pos_w_sum = weight_mono_i[weight_mono_i > 0].sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "weight_mono_i[weight_mono_i > 0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 5, 5\n",
    "mb.pl.kmer_enrichment(model, train, log_scale=False, style='scatter', ylab='t1', xlab='p1', k=-1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mb.pl.conv(model)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "mubind",
   "language": "python",
   "display_name": "mubind"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}