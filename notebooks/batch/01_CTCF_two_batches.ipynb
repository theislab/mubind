{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "06723943-4395-4e31-9cc8-8e1e5bd5dc4c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "ce3c3d59-4088-4033-98a5-ed452c8c6d38",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import mubind as mb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import bindome as bd\n",
    "bd.constants.ANNOTATIONS_DIRECTORY = '../../annotations'\n",
    "# mb.models.MultiBind\n",
    "import torch.optim as topti\n",
    "import torch.utils.data as tdata\n",
    "import matplotlib.pyplot as plt\n",
    "import logomaker\n",
    "\n",
    "# Use a GPU if available, as it should be faster.\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device: \" + str(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def _mismatch(word, letters, num_mismatches):\n",
    "    for locs in itertools.combinations(range(len(word)), num_mismatches):\n",
    "        this_word = [[char] for char in word]\n",
    "        for loc in locs:\n",
    "            orig_char = word[loc]\n",
    "            this_word[loc] = [l for l in letters if l != orig_char]\n",
    "        for poss in itertools.product(*this_word):\n",
    "            yield \"\".join(poss)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [],
   "source": [
    "# motif = \"ATT\"\n",
    "# x2, y2 = mb.datasets.simulate_xy(motif, n_trials=2100, seqlen=len(motif) + 1, max_mismatches=min(len(motif), 2), counts_size=1)\n",
    "# x2, y2\n",
    "# df = pd.DataFrame(data=y2)\n",
    "# df.columns = [1]\n",
    "# df.index = x2\n",
    "# df[0] = 0\n",
    "# df = df[[0, 1]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "be8b3b18-1b3d-49c8-8252-320bb1b971c5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = mb.bindome.datasets.ProBound.ctcf(flank_length=0)\n",
    "df = df.sort_values(1, ascending=False).reset_index(drop=True)\n",
    "# data = df.head(1000)\n",
    "data = df.copy()\n",
    "# data = df.sample(1500, random_state=50)\n",
    "# data = df.copy()\n",
    "data.index = data['seq']\n",
    "\n",
    "# remove as many nucleotides as posisble (faster training/convergence)\n",
    "data.index = data.index.astype(str).str[45:]\n",
    "\n",
    "\n",
    "# data.index = data.index.astype(str).str[-15:]\n",
    "del data['seq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "outputs": [
    {
     "data": {
      "text/plain": "(120096, 2)"
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "9fbc2e5d-53f4-4ef2-8141-be4063dca629",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = data.sample(data.shape[0], random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "outputs": [],
   "source": [
    "# # define batches\n",
    "# batch = np.random.randint(2, size=data.shape[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "outputs": [],
   "source": [
    "# # data[batch == 0] = data[batch == 0] + 20\n",
    "# # data[batch == 1] = data[batch == 1] + 10\n",
    "# data['batch'] = batch\n",
    "#\n",
    "# data = data[data['batch'] == 1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "c7feab1b-1726-4d88-b57a-060b6c8b6323",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from matplotlib import rcParams\n",
    "rcParams['figure.figsize'] = 5, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "0301f36d-c2fd-4b03-9c12-e06b7c6c1db7",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading object (# entries) 120096\n",
      "(120096, 2)\n"
     ]
    }
   ],
   "source": [
    "# TODO: skipped for now\n",
    "n_rounds = 1\n",
    "\n",
    "print('loading object (# entries)', data.shape[0])\n",
    "dataset = mb.datasets.SelexDataset(data, n_rounds=n_rounds, labels=[0, 1])\n",
    "train = tdata.DataLoader(dataset=dataset,\n",
    "                         # batch_size=256,\n",
    "                         batch_size=512,\n",
    "                         shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "e1620ebe-cbb2-4bc8-a0f6-bfd60b3f117a",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "49c04087-128d-4680-8b0e-c3f488fa7654",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The line_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext line_profiler\n"
     ]
    }
   ],
   "source": [
    "%load_ext line_profiler\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "outputs": [],
   "source": [
    "# %lprun -f mb.tl.train_network mb.tl.train_network(model, train, device, next_optimiser, criterion, num_epochs=20, early_stopping=100, log_each=2, dirichlet_regularization=0, exp_max=40, verbose=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "outputs": [],
   "source": [
    "# %lprun -f mb.tl.train_iterative mb.tl.train_iterative(train, device, w=18, show_logo=False, opt_kernel_shift=0, opt_kernel_length=0, dirichlet_regularization=dirichlet_regularization, lr=[0.01, 0.01], weight_decay=[0.01, 0.001], ignore_kernel=ignore_kernel, num_epochs=2, early_stopping=100, use_dinuc=False, n_kernels=n_kernels, log_each=log_each, stop_at_kernel=None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(nan)"
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = torch.tensor(data.copy().to_numpy() - 100)\n",
    "y_true = torch.tensor(data.copy().to_numpy() - 100)\n",
    "torch.mean(y_pred - y_true * torch.log(y_pred))\n",
    "torch.log(y_pred)\n",
    "criterion = mb.tl.PoissonLoss()\n",
    "criterion(y_pred, y_true)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7475742f-41cd-4c70-bab5-eea4985f2cfa",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "##NEW JOB\n",
      "ignore kernel 1\n",
      "next w 15 <class 'int'>\n",
      "# rounds 1\n",
      "# batches 1\n",
      "# enr_series True\n",
      "\n",
      "Kernel to optimize 0\n",
      "\n",
      "FREEZING KERNELS\n",
      "setting grad status of kernel at 0 to 1\n",
      "setting grad status of kernel at 1 to 0\n",
      "\n",
      "\n",
      "kernels mask [0 1]\n",
      "optimizing using <class 'torch.optim.adam.Adam'> and <class 'mubind.tl.loss.PoissonLoss'> n_epochs 100 early_stopping 10\n",
      "lr= 0.01, weight_decay= 0.01, dir weight= 0\n",
      "Epoch:  3, Loss: 0.843945 , best epoch: 1 secs per epoch: 18.697 s\n",
      "Epoch:  5, Loss: 0.843948 , best epoch: 1 secs per epoch: 17.334 s\n",
      "Epoch:  7, Loss: 0.843949 , best epoch: 1 secs per epoch: 16.854 s\n",
      "Epoch:  9, Loss: 0.843949 , best epoch: 1 secs per epoch: 16.588 s\n",
      "Epoch: 11, Loss: 0.843949 , best epoch: 1 secs per epoch: 16.774 s\n",
      "Epoch: 12, Loss: 0.8439 , best epoch: 1 secs per epoch: 18.146 s\n",
      "early stop!\n",
      "total time: 199.60410070419312s 12\n",
      "secs per epoch: 18.146 s\n",
      "\n",
      "Kernel to optimize 1\n",
      "\n",
      "FREEZING KERNELS\n",
      "setting grad status of kernel at 0 to 0\n",
      "setting grad status of kernel at 1 to 1\n",
      "\n",
      "\n",
      "kernels mask [0 0]\n",
      "optimizing using <class 'torch.optim.adam.Adam'> and <class 'mubind.tl.loss.PoissonLoss'> n_epochs 100 early_stopping 100\n",
      "lr= 0.01, weight_decay= 0.001, dir weight= 0\n",
      "Epoch:  3, Loss: 0.842519 , best epoch: 1 secs per epoch: 19.117 s\n",
      "Epoch:  5, Loss: 0.842211 , best epoch: 3 secs per epoch: 17.987 s\n",
      "Epoch:  7, Loss: 0.841960 , best epoch: 5 secs per epoch: 17.607 s\n",
      "Epoch:  9, Loss: 0.840787 , best epoch: 7 secs per epoch: 17.689 s\n",
      "Epoch: 11, Loss: 0.840159 , best epoch: 9 secs per epoch: 17.516 s\n",
      "Epoch: 13, Loss: 0.839463 , best epoch: 11 secs per epoch: 17.363 s\n",
      "Epoch: 15, Loss: 0.837382 , best epoch: 13 secs per epoch: 17.470 s\n",
      "Epoch: 17, Loss: 0.837204 , best epoch: 15 secs per epoch: 17.495 s\n",
      "Epoch: 19, Loss: 0.835547 , best epoch: 17 secs per epoch: 17.558 s\n"
     ]
    }
   ],
   "source": [
    "# assign batch and data type\n",
    "\n",
    "# data['batch'] = 0\n",
    "# data['is_count_data'] = 1\n",
    "# n_batches=3\n",
    "\n",
    "dirichlet_regularization = 0\n",
    "# for dirichlet_regularization_log in range(-5, 3):\n",
    "\n",
    "n_epochs = 100\n",
    "log_each = 2\n",
    "n_kernels = 2\n",
    "w = 15 # min(len(motif), 6)\n",
    "opt_kernel_shift=1\n",
    "opt_kernel_length=1\n",
    "\n",
    "from matplotlib import rcParams\n",
    "rcParams['figure.figsize'] = 8, 1\n",
    "\n",
    "import time\n",
    "t0 = time.time()\n",
    "\n",
    "criterion = mb.tl.PoissonLoss()\n",
    "\n",
    "for ignore_kernel in [1]: # [0, 1]:\n",
    "    print('\\n\\n##NEW JOB')\n",
    "    print('ignore kernel', ignore_kernel)\n",
    "    model_by_k, res_next = mb.tl.train_iterative(train, device, w=w, show_logo=0, criterion=criterion,\n",
    "                                                 opt_kernel_shift=0, opt_kernel_length=0,\n",
    "                                                 dirichlet_regularization=dirichlet_regularization, # 10 ** dirichlet_regularization_log,\n",
    "                                                 lr=[0.01, 0.01], weight_decay=[0.01, 0.001], ignore_kernel=ignore_kernel,\n",
    "                                                 num_epochs=n_epochs, early_stopping=[10, 100], use_dinuc=False, # optimiser=torch.optim.LBFGS,\n",
    "                                                 n_kernels=n_kernels, log_each=log_each, stop_at_kernel=None) #  seed=seed) # seeds.index[0]) #\n",
    "    print('##DONE....\\n\\n')\n",
    "\n",
    "\n",
    "print('total time: %.3f s' % ((time.time() - t0)))\n",
    "# res = []\n",
    "# model_by_k = {}\n",
    "\n",
    "model = model_by_k\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbd5c33-a070-43f4-bc65-d51aa2b4cc02",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### We can visualize the overall results obtained by the network, once the training is finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import mubind as mb"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = model_by_k\n",
    "mb.tl.scores(model, train)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "counts = mb.tl.predict(model, train)\n",
    "counts"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mb.pl.kmer_enrichment(model, train, log_scale=False, style='scatter', ylab='t1', xlab='p1')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mb.pl.conv_mono(model)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mubind]",
   "language": "python",
   "name": "conda-env-mubind-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "21beeb3f351c8e886a898db8b4cccf8d4f8a70210033cb08b23469d9f8df079c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}