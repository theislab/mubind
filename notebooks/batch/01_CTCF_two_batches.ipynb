{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/ignacio.ibarra/Dropbox/workspace/theislab/mubind/notebooks/batch\n"
     ]
    }
   ],
   "source": [
    "cd workspace/theislab/mubind/notebooks/batch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rio/miniconda3/envs/mubind/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import mubind as mb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import bindome as bd\n",
    "bd.constants.ANNOTATIONS_DIRECTORY = '../../annotations'\n",
    "# mb.models.MultiBind\n",
    "import torch.optim as topti\n",
    "import torch.utils.data as tdata\n",
    "import matplotlib.pyplot as plt\n",
    "import logomaker\n",
    "\n",
    "# Use a GPU if available, as it should be faster.\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device: \" + str(device))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# motif = \"ATT\"\n",
    "# x2, y2 = mb.datasets.simulate_xy(motif, n_trials=2100, seqlen=len(motif) + 1, max_mismatches=min(len(motif), 2), counts_size=1)\n",
    "# x2, y2\n",
    "# df = pd.DataFrame(data=y2)\n",
    "# df.columns = [1]\n",
    "# df.index = x2\n",
    "# df[0] = 0\n",
    "# df = df[[0, 1]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "df = mb.bindome.datasets.ProBound.ctcf(flank_length=0)\n",
    "df = df.sort_values(1, ascending=False).reset_index(drop=True)\n",
    "# data = df.head(1000)\n",
    "# data = df.copy()\n",
    "\n",
    "df.index = df['seq']\n",
    "del df['seq']\n",
    "df.index = df.index.astype(str).str[45:]\n",
    "\n",
    "df = df[~df.index.duplicated(keep='first')]\n",
    "\n",
    "data = df.sample(2500)\n",
    "# data = mb.pp.sample_rounds(df, 2, 10000)\n",
    "\n",
    "# remove as many nucleotides as posisble (faster training/convergence)\n",
    "\n",
    "\n",
    "# data.index = data.index.astype(str).str[-15:]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "from matplotlib import rcParams\n",
    "rcParams['figure.figsize'] = 5, 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading object (# entries) 2500\n"
     ]
    }
   ],
   "source": [
    "# TODO: skipped for now\n",
    "n_rounds = 2\n",
    "\n",
    "print('loading object (# entries)', data.shape[0])\n",
    "dataset = mb.datasets.SelexDataset(data, n_rounds=n_rounds, labels=[0, 1])\n",
    "train = tdata.DataLoader(dataset=dataset,\n",
    "                         # batch_size=256,\n",
    "                         batch_size=512,\n",
    "                         shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The line_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext line_profiler\n"
     ]
    }
   ],
   "source": [
    "%load_ext line_profiler\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# %lprun -f mb.tl.train_network mb.tl.train_network(model, train, device, next_optimiser, criterion, num_epochs=20, early_stopping=100, log_each=2, dirichlet_regularization=0, exp_max=40, verbose=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "# %lprun -f mb.tl.train_iterative mb.tl.train_iterative(train, device, w=18, show_logo=False, opt_kernel_shift=0, opt_kernel_length=0, dirichlet_regularization=dirichlet_regularization, lr=[0.01, 0.01], weight_decay=[0.01, 0.001], ignore_kernel=ignore_kernel, num_epochs=2, early_stopping=100, use_dinuc=False, n_kernels=n_kernels, log_each=log_each, stop_at_kernel=None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "pd.set_option('display.expand_frame_repr', False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "##NEW JOB\n",
      "ignore kernel 1\n",
      "# trials 2500\n",
      "next w 15 <class 'int'>\n",
      "# rounds {2}\n",
      "# rounds {2}\n",
      "# use_mono True\n",
      "# use_dinuc True\n",
      "# batches 1\n",
      "# kernels 3\n",
      "# initial w 15\n",
      "# enr_series True\n",
      "\n",
      "Kernel to optimize 0\n",
      "\n",
      "FREEZING KERNELS\n",
      "optimizing feature type mono\n",
      "setting grad status of kernel (mono, dinuc) at 0 to (1, 0)\n",
      "setting grad status of kernel (mono, dinuc) at 1 to (0, 0)\n",
      "setting grad status of kernel (mono, dinuc) at 2 to (0, 0)\n",
      "\n",
      "\n",
      "kernels mask [0 1 1]\n",
      "optimizer:  <class 'torch.optim.adam.Adam'> \n",
      "criterion: <class 'mubind.tl.loss.PoissonLoss'> \n",
      "# epochs: 200 \n",
      "early_stopping: 5\n",
      "lr= 0.01, weight_decay= 0.01, dir weight= 0\n",
      "Epoch: 101, Loss: 0.843895 , best epoch: 99 secs per epoch: 0.053 s\n",
      "Final loss: 0.8437027097\n",
      "Total time (model/function): (10.550s / 10.550s)\n",
      "Time per epoch (model/function): (0.053s/ 0.053s)\n",
      "Time per epoch per 1k trials: 0.021s\n",
      "Current time: 2022-12-25 11:56:47.017075\n",
      "optimization of dinuc is not necessary for the intercepts (kernel=0). Skip...\n",
      "\n",
      "Kernel to optimize 1\n",
      "\n",
      "FREEZING KERNELS\n",
      "optimizing feature type mono\n",
      "setting grad status of kernel (mono, dinuc) at 0 to (0, 0)\n",
      "setting grad status of kernel (mono, dinuc) at 1 to (1, 0)\n",
      "setting grad status of kernel (mono, dinuc) at 2 to (0, 0)\n",
      "\n",
      "\n",
      "kernels mask [0 0 1]\n",
      "optimizer:  <class 'torch.optim.adam.Adam'> \n",
      "criterion: <class 'mubind.tl.loss.PoissonLoss'> \n",
      "# epochs: 200 \n",
      "early_stopping: 25\n",
      "lr= 0.01, weight_decay= 0.001, dir weight= 0\n",
      "Epoch: 101, Loss: 0.834245 , best epoch: 99 secs per epoch: 0.059 s\n",
      "Final loss: 0.8305037141\n",
      "Total time (model/function): (21.573s / 11.024s)\n",
      "Time per epoch (model/function): (0.108s/ 0.055s)\n",
      "Time per epoch per 1k trials: 0.022s\n",
      "Current time: 2022-12-25 11:56:58.042960\n",
      "\n",
      "WIDTH OPTIMIZATION (first)...\n",
      "options to try [[0, 0, 0], [0, 1, 0], [0, 2, 0], [1, 0, 0], [1, 1, 0], [1, 2, 0], [2, 0, 0], [2, 1, 0], [2, 2, 0]]\n",
      "next expand left: 0, next expand right: 0, shift: 0\n",
      "optimizer:  <class 'torch.optim.adam.Adam'> \n",
      "criterion: <class 'mubind.tl.loss.PoissonLoss'> \n",
      "# epochs: 200 \n",
      "early_stopping: 25\n",
      "lr= 0.01, weight_decay= 0.001, dir weight= 0\n",
      "Final loss: 0.8268282652\n",
      "Total time (model/function): (36.021s / 14.447s)\n",
      "Time per epoch (model/function): (0.181s/ 0.073s)\n",
      "Time per epoch per 1k trials: 0.029s\n",
      "Current time: 2022-12-25 11:57:12.499770\n",
      "\n",
      "next expand left: 0, next expand right: 1, shift: 0\n",
      "optimizer:  <class 'torch.optim.adam.Adam'> \n",
      "criterion: <class 'mubind.tl.loss.PoissonLoss'> \n",
      "# epochs: 200 \n",
      "early_stopping: 25\n",
      "lr= 0.01, weight_decay= 0.001, dir weight= 0\n",
      "Final loss: 0.8261602163\n",
      "Total time (model/function): (32.238s / 10.664s)\n",
      "Time per epoch (model/function): (0.162s/ 0.054s)\n",
      "Time per epoch per 1k trials: 0.021s\n",
      "Current time: 2022-12-25 11:57:23.166814\n",
      "\n",
      "next expand left: 0, next expand right: 2, shift: 0\n",
      "optimizer:  <class 'torch.optim.adam.Adam'> \n",
      "criterion: <class 'mubind.tl.loss.PoissonLoss'> \n",
      "# epochs: 200 \n",
      "early_stopping: 25\n",
      "lr= 0.01, weight_decay= 0.001, dir weight= 0\n",
      "Final loss: 0.8259867787\n",
      "Total time (model/function): (32.670s / 11.097s)\n",
      "Time per epoch (model/function): (0.164s/ 0.056s)\n",
      "Time per epoch per 1k trials: 0.022s\n",
      "Current time: 2022-12-25 11:57:34.266688\n",
      "\n",
      "next expand left: 1, next expand right: 0, shift: 0\n",
      "optimizer:  <class 'torch.optim.adam.Adam'> \n",
      "criterion: <class 'mubind.tl.loss.PoissonLoss'> \n",
      "# epochs: 200 \n",
      "early_stopping: 25\n",
      "lr= 0.01, weight_decay= 0.001, dir weight= 0\n",
      "Final loss: 0.8261374474\n",
      "Total time (model/function): (33.094s / 11.520s)\n",
      "Time per epoch (model/function): (0.166s/ 0.058s)\n",
      "Time per epoch per 1k trials: 0.023s\n",
      "Current time: 2022-12-25 11:57:45.790374\n",
      "\n",
      "next expand left: 1, next expand right: 1, shift: 0\n",
      "optimizer:  <class 'torch.optim.adam.Adam'> \n",
      "criterion: <class 'mubind.tl.loss.PoissonLoss'> \n",
      "# epochs: 200 \n",
      "early_stopping: 25\n",
      "lr= 0.01, weight_decay= 0.001, dir weight= 0\n",
      "Final loss: 0.8254643440\n",
      "Total time (model/function): (32.833s / 11.260s)\n",
      "Time per epoch (model/function): (0.165s/ 0.057s)\n",
      "Time per epoch per 1k trials: 0.023s\n",
      "Current time: 2022-12-25 11:57:57.053376\n",
      "\n",
      "next expand left: 1, next expand right: 2, shift: 0\n",
      "optimizer:  <class 'torch.optim.adam.Adam'> \n",
      "criterion: <class 'mubind.tl.loss.PoissonLoss'> \n",
      "# epochs: 200 \n",
      "early_stopping: 25\n",
      "lr= 0.01, weight_decay= 0.001, dir weight= 0\n",
      "Final loss: 0.8253319860\n",
      "Total time (model/function): (34.598s / 13.024s)\n",
      "Time per epoch (model/function): (0.174s/ 0.065s)\n",
      "Time per epoch per 1k trials: 0.026s\n",
      "Current time: 2022-12-25 11:58:10.081074\n",
      "\n",
      "next expand left: 2, next expand right: 0, shift: 0\n",
      "optimizer:  <class 'torch.optim.adam.Adam'> \n",
      "criterion: <class 'mubind.tl.loss.PoissonLoss'> \n",
      "# epochs: 200 \n",
      "early_stopping: 25\n",
      "lr= 0.01, weight_decay= 0.001, dir weight= 0\n",
      "Final loss: 0.8257721424\n",
      "Total time (model/function): (34.496s / 12.922s)\n",
      "Time per epoch (model/function): (0.173s/ 0.065s)\n",
      "Time per epoch per 1k trials: 0.026s\n",
      "Current time: 2022-12-25 11:58:23.007010\n",
      "\n",
      "next expand left: 2, next expand right: 1, shift: 0\n",
      "optimizer:  <class 'torch.optim.adam.Adam'> \n",
      "criterion: <class 'mubind.tl.loss.PoissonLoss'> \n",
      "# epochs: 200 \n",
      "early_stopping: 25\n",
      "lr= 0.01, weight_decay= 0.001, dir weight= 0\n",
      "Final loss: 0.8249871492\n",
      "Total time (model/function): (35.005s / 13.432s)\n",
      "Time per epoch (model/function): (0.176s/ 0.067s)\n",
      "Time per epoch per 1k trials: 0.027s\n",
      "Current time: 2022-12-25 11:58:36.443373\n",
      "\n",
      "next expand left: 2, next expand right: 2, shift: 0\n",
      "optimizer:  <class 'torch.optim.adam.Adam'> \n",
      "criterion: <class 'mubind.tl.loss.PoissonLoss'> \n",
      "# epochs: 200 \n",
      "early_stopping: 25\n",
      "lr= 0.01, weight_decay= 0.001, dir weight= 0\n",
      "Final loss: 0.8247614145\n",
      "Total time (model/function): (36.005s / 14.432s)\n",
      "Time per epoch (model/function): (0.181s/ 0.073s)\n",
      "Time per epoch per 1k trials: 0.029s\n",
      "Current time: 2022-12-25 11:58:50.878533\n",
      "\n",
      "sorted\n",
      "   expand.left  expand.right  shift  pos_w_sum  width  loss_diff_pct      loss  last_loss\n",
      "0            2             2      0  10.122150     19       0.691424  0.824761   0.830504\n",
      "1            2             1      0   9.913689     18       0.664243  0.824987   0.830504\n",
      "2            1             2      0   9.554348     18       0.622722  0.825332   0.830504\n",
      "3            1             1      0   9.462379     17       0.606785  0.825464   0.830504\n",
      "4            2             0      0   9.424967     17       0.569723  0.825772   0.830504\n",
      "5            0             2      0   8.943790     17       0.543879  0.825987   0.830504\n",
      "6            1             0      0   9.020684     16       0.525737  0.826137   0.830504\n",
      "7            0             1      0   8.815498     16       0.522996  0.826160   0.830504\n",
      "8            0             0      0   8.401022     15       0.442557  0.826828   0.830504\n",
      "9            0             0      0  10.122150     19       0.000000  0.830504   0.830504\n",
      "2 2 0 10.122150421142578 19 0.6914237058001876 0.8247614145278931\n",
      "action (expand left, expand right, shift): (2, 2, 0)\n",
      "\n",
      "\n",
      "WIDTH OPTIMIZATION (again)...\n",
      "options to try [[0, 0, 0], [0, 1, 0], [0, 2, 0], [1, 0, 0], [1, 1, 0], [1, 2, 0], [2, 0, 0], [2, 1, 0], [2, 2, 0]]\n",
      "next expand left: 0, next expand right: 0, shift: 0\n",
      "optimizer:  <class 'torch.optim.adam.Adam'> \n",
      "criterion: <class 'mubind.tl.loss.PoissonLoss'> \n",
      "# epochs: 200 \n",
      "early_stopping: 25\n",
      "lr= 0.01, weight_decay= 0.001, dir weight= 0\n",
      "Epoch: 31, Loss: 0.8248 , best epoch: 5 secs per epoch: 0.066 s\n",
      "early stop!\n",
      "Final loss: 0.8247549415\n",
      "Total time (model/function): (37.986s / 1.980s)\n",
      "Time per epoch (model/function): (1.266s/ 0.066s)\n",
      "Time per epoch per 1k trials: 0.026s\n",
      "Current time: 2022-12-25 11:58:52.872431\n",
      "\n",
      "next expand left: 0, next expand right: 1, shift: 0\n",
      "optimizer:  <class 'torch.optim.adam.Adam'> \n",
      "criterion: <class 'mubind.tl.loss.PoissonLoss'> \n",
      "# epochs: 200 \n",
      "early_stopping: 25\n",
      "lr= 0.01, weight_decay= 0.001, dir weight= 0\n",
      "Epoch: 48, Loss: 0.8246 , best epoch: 22 secs per epoch: 0.072 s\n",
      "early stop!\n",
      "Final loss: 0.8246355414\n",
      "Total time (model/function): (39.393s / 3.387s)\n",
      "Time per epoch (model/function): (0.838s/ 0.072s)\n",
      "Time per epoch per 1k trials: 0.029s\n",
      "Current time: 2022-12-25 11:58:56.263781\n",
      "\n",
      "next expand left: 1, next expand right: 0, shift: 0\n",
      "optimizer:  <class 'torch.optim.adam.Adam'> \n",
      "criterion: <class 'mubind.tl.loss.PoissonLoss'> \n",
      "# epochs: 200 \n",
      "early_stopping: 25\n",
      "lr= 0.01, weight_decay= 0.001, dir weight= 0\n",
      "Final loss: 0.8245030165\n",
      "Total time (model/function): (51.277s / 15.272s)\n",
      "Time per epoch (model/function): (0.258s/ 0.077s)\n",
      "Time per epoch per 1k trials: 0.031s\n",
      "Current time: 2022-12-25 11:59:11.541106\n",
      "\n",
      "sorted\n",
      "   expand.left  expand.right  shift  pos_w_sum  width  loss_diff_pct      loss  last_loss\n",
      "0            1             0      0  10.475267     20       0.031330  0.824503   0.824761\n",
      "1            0             1      0  10.285690     20       0.016544  0.824625   0.824761\n",
      "2            0             0      0  10.119182     19       0.006597  0.824707   0.824761\n",
      "3            0             0      0  10.475267     20       0.000000  0.824761   0.824761\n",
      "1 0 0 10.47526741027832 20 0.03133003696326547 0.8245030164718627\n",
      "action (expand left, expand right, shift): (1, 0, 0)\n",
      "\n",
      "\n",
      "WIDTH OPTIMIZATION (again)...\n",
      "Reached maximum w. Stop...\n",
      "\n",
      "SHIFT OPTIMIZATION (first)...\n",
      "options to try [[0, 0, -2], [0, 0, -1], [0, 0, 0], [0, 0, 1], [0, 0, 2]]\n",
      "next expand left: 0, next expand right: 0, shift: -2\n",
      "optimizer:  <class 'torch.optim.adam.Adam'> \n",
      "criterion: <class 'mubind.tl.loss.PoissonLoss'> \n",
      "# epochs: 600 \n",
      "early_stopping: 25\n",
      "lr= 0.01, weight_decay= 0.001, dir weight= 0\n",
      "Epoch: 515, Loss: 0.8243 , best epoch: 489 secs per epoch: 0.067 s\n",
      "early stop!\n",
      "Final loss: 0.8242682457\n",
      "Total time (model/function): (85.809s / 34.532s)\n",
      "Time per epoch (model/function): (0.167s/ 0.067s)\n",
      "Time per epoch per 1k trials: 0.027s\n",
      "Current time: 2022-12-25 11:59:46.088696\n",
      "\n",
      "next expand left: 0, next expand right: 0, shift: -1\n",
      "optimizer:  <class 'torch.optim.adam.Adam'> \n",
      "criterion: <class 'mubind.tl.loss.PoissonLoss'> \n",
      "# epochs: 600 \n",
      "early_stopping: 25\n",
      "lr= 0.01, weight_decay= 0.001, dir weight= 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [25], line 32\u001B[0m\n\u001B[1;32m     30\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mignore kernel\u001B[39m\u001B[38;5;124m'\u001B[39m, ignore_kernel)\n\u001B[1;32m     31\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m# trials\u001B[39m\u001B[38;5;124m'\u001B[39m, data\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m])\n\u001B[0;32m---> 32\u001B[0m     model_by_k, res_next \u001B[38;5;241m=\u001B[39m \u001B[43mmb\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtl\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptimize_iterative\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mw\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mw\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshow_logo\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     33\u001B[0m \u001B[43m                                                 \u001B[49m\u001B[43mopt_kernel_shift\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mopt_kernel_shift\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mopt_kernel_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mopt_kernel_length\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     34\u001B[0m \u001B[43m                                                 \u001B[49m\u001B[43mdirichlet_regularization\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdirichlet_regularization\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;66;43;03m# 10 ** dirichlet_regularization_log,\u001B[39;49;00m\n\u001B[1;32m     35\u001B[0m \u001B[43m                                                 \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwd\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mignore_kernel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mignore_kernel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muse_mono\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     36\u001B[0m \u001B[43m                                                 \u001B[49m\u001B[43mnum_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_epochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mearly_stopping\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mearly_stopping\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muse_dinuc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;66;43;03m# optimiser=torch.optim.LBFGS,\u001B[39;49;00m\n\u001B[1;32m     37\u001B[0m \u001B[43m                                                 \u001B[49m\u001B[43mn_kernels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_kernels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlog_each\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlog_each\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop_at_kernel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m \u001B[38;5;66;03m#  seed=seed) # seeds.index[0]) #\u001B[39;00m\n\u001B[1;32m     38\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m##DONE....\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     42\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtotal time: \u001B[39m\u001B[38;5;132;01m%.3f\u001B[39;00m\u001B[38;5;124m s\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m%\u001B[39m ((time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m t0)))\n",
      "File \u001B[0;32m/mnt/c/Users/ignacio.ibarra/Dropbox/workspace/theislab/mubind/mubind/tl/prediction.py:506\u001B[0m, in \u001B[0;36moptimize_iterative\u001B[0;34m(train, device, n_kernels, w, max_w, num_epochs, early_stopping, log_each, opt_kernel_shift, opt_kernel_length, expand_length_max, expand_length_step, show_logo, optimiser, criterion, seed, init_random, joint_learning, ignore_kernel, lr, weight_decay, stop_at_kernel, dirichlet_regularization, verbose, exp_max, shift_max, shift_step, use_mono, use_dinuc, r2_per_epoch, **kwargs)\u001B[0m\n\u001B[1;32m    501\u001B[0m \u001B[38;5;66;03m# print(model_by_k[k_parms].loss_color)\u001B[39;00m\n\u001B[1;32m    502\u001B[0m \u001B[38;5;66;03m#######\u001B[39;00m\n\u001B[1;32m    503\u001B[0m \u001B[38;5;66;03m# optimize the flanks through +1/-1 shifts\u001B[39;00m\n\u001B[1;32m    504\u001B[0m \u001B[38;5;66;03m#######\u001B[39;00m\n\u001B[1;32m    505\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (opt_kernel_shift \u001B[38;5;129;01mor\u001B[39;00m opt_kernel_length) \u001B[38;5;129;01mand\u001B[39;00m i \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m--> 506\u001B[0m     model \u001B[38;5;241m=\u001B[39m \u001B[43moptimize_width_and_length\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    507\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    508\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    509\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43mexpand_length_max\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    510\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43mexpand_length_step\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    511\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43mshift_max\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    512\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43mshift_step\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    513\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    514\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43mfeat_i\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfeat_i\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    515\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43mcolors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcolors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    516\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    517\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnext_lr\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    518\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnext_weight_decay\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    519\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43moptimiser\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptimiser\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    520\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43mlog_each\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlog_each\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    521\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43mexp_max\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mexp_max\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    522\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43mdirichlet_regularization\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdirichlet_regularization\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    523\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43mearly_stopping\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnext_early_stopping\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    524\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43mshow_logo\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mshow_logo\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    525\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43mn_kernels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_kernels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    526\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43mw\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mw\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    527\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43mmax_w\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_w\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    528\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43mnum_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_epochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    529\u001B[0m \u001B[43m                                      \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    531\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m show_logo:\n\u001B[1;32m    532\u001B[0m     vprint(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mafter shift optimz model\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m/mnt/c/Users/ignacio.ibarra/Dropbox/workspace/theislab/mubind/mubind/tl/prediction.py:673\u001B[0m, in \u001B[0;36moptimize_width_and_length\u001B[0;34m(train, model, device, expand_length_max, expand_length_step, shift_max, shift_step, i, colors, verbose, lr, weight_decay, optimiser, log_each, exp_max, num_epochs_shift_factor, dirichlet_regularization, early_stopping, criterion, show_logo, feat_i, n_kernels, w, max_w, num_epochs, loss_thr_pct, **kwargs)\u001B[0m\n\u001B[1;32m    670\u001B[0m model_shift\u001B[38;5;241m.\u001B[39mr2_history \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m    671\u001B[0m model_shift\u001B[38;5;241m.\u001B[39mloss_color \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m--> 673\u001B[0m \u001B[43mmb\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtl\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptimize_modified_kernel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    674\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel_shift\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    675\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    676\u001B[0m \u001B[43m    \u001B[49m\u001B[43mkernel_i\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    677\u001B[0m \u001B[43m    \u001B[49m\u001B[43mshift\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mshift\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    678\u001B[0m \u001B[43m    \u001B[49m\u001B[43mexpand_left\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mexpand_left\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    679\u001B[0m \u001B[43m    \u001B[49m\u001B[43mexpand_right\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mexpand_right\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    680\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    681\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnum_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_epochs\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mopt_option_text\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mWIDTH\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mnum_epochs\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mnum_epochs_shift_factor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    682\u001B[0m \u001B[43m    \u001B[49m\u001B[43mearly_stopping\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mearly_stopping\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    683\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlog_each\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_epochs\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mopt_option_text\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mWIDTH\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mnum_epochs\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mnum_epochs_shift_factor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;66;43;03m# log_each,\u001B[39;49;00m\n\u001B[1;32m    684\u001B[0m \u001B[43m    \u001B[49m\u001B[43mupdate_grad_i\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    685\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfeat_i\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfeat_i\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    686\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlr\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    687\u001B[0m \u001B[43m    \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mweight_decay\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    688\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptimiser\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptimiser\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    689\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    690\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdirichlet_regularization\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdirichlet_regularization\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    691\u001B[0m \u001B[43m    \u001B[49m\u001B[43mexp_max\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mexp_max\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    692\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    693\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    694\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    695\u001B[0m vprint(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    697\u001B[0m model_shift\u001B[38;5;241m.\u001B[39mloss_color \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(np\u001B[38;5;241m.\u001B[39mrepeat(next_color, \u001B[38;5;28mlen\u001B[39m(model_shift\u001B[38;5;241m.\u001B[39mloss_history)))\n",
      "File \u001B[0;32m/mnt/c/Users/ignacio.ibarra/Dropbox/workspace/theislab/mubind/mubind/tl/prediction.py:798\u001B[0m, in \u001B[0;36moptimize_modified_kernel\u001B[0;34m(model, train, shift, expand_left, expand_right, device, num_epochs, early_stopping, log_each, feat_i, update_grad_i, use_dinuc, kernel_i, lr, weight_decay, optimiser, criterion, dirichlet_regularization, exp_max, verbose, **kwargs)\u001B[0m\n\u001B[1;32m    795\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m criterion \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    796\u001B[0m     criterion \u001B[38;5;241m=\u001B[39m mb\u001B[38;5;241m.\u001B[39mtl\u001B[38;5;241m.\u001B[39mPoissonLoss()\n\u001B[0;32m--> 798\u001B[0m \u001B[43moptimize_simple\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    799\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    800\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    801\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    802\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptimiser\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    803\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    804\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnum_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_epochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    805\u001B[0m \u001B[43m    \u001B[49m\u001B[43mearly_stopping\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mearly_stopping\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    806\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlog_each\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlog_each\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    807\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdirichlet_regularization\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdirichlet_regularization\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    808\u001B[0m \u001B[43m    \u001B[49m\u001B[43mexp_max\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mexp_max\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    809\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    810\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    812\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m model\n",
      "File \u001B[0;32m/mnt/c/Users/ignacio.ibarra/Dropbox/workspace/theislab/mubind/mubind/tl/prediction.py:201\u001B[0m, in \u001B[0;36moptimize_simple\u001B[0;34m(model, dataloader, device, optimiser, criterion, num_epochs, early_stopping, dirichlet_regularization, exp_max, log_each, verbose, r2_per_epoch)\u001B[0m\n\u001B[1;32m    199\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m exp_max \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    200\u001B[0m     loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mexp_barrier(exp_max)\n\u001B[0;32m--> 201\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Calculate gradients.\u001B[39;00m\n\u001B[1;32m    202\u001B[0m optimiser\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m    203\u001B[0m outputs \u001B[38;5;241m=\u001B[39m model(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39minputs)  \u001B[38;5;66;03m# Forward pass through the network.\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/mubind/lib/python3.10/site-packages/torch/_tensor.py:396\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    387\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    388\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    389\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    390\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    394\u001B[0m         create_graph\u001B[38;5;241m=\u001B[39mcreate_graph,\n\u001B[1;32m    395\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs)\n\u001B[0;32m--> 396\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/mubind/lib/python3.10/site-packages/torch/autograd/__init__.py:173\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    168\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    170\u001B[0m \u001B[38;5;66;03m# The reason we repeat same the comment below is that\u001B[39;00m\n\u001B[1;32m    171\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    172\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 173\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    174\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    175\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# assign batch and data type\n",
    "\n",
    "# data['batch'] = 0\n",
    "# data['is_count_data'] = 1\n",
    "# n_batches=3\n",
    "\n",
    "dirichlet_regularization = 0\n",
    "# for dirichlet_regularization_log in range(-5, 3):\n",
    "\n",
    "n_epochs = 200\n",
    "log_each = 100\n",
    "n_kernels = 3\n",
    "w = 15 # min(len(motif), 6)\n",
    "lr = [0.01] * n_kernels\n",
    "wd = [0.01,] + [0.001] * (n_kernels - 1)\n",
    "early_stopping = [5,] + [25] * (n_kernels - 1)\n",
    "opt_kernel_shift = 1\n",
    "opt_kernel_length = 1\n",
    "\n",
    "from matplotlib import rcParams\n",
    "rcParams['figure.figsize'] = 8, 1\n",
    "\n",
    "import time\n",
    "t0 = time.time()\n",
    "\n",
    "criterion = mb.tl.PoissonLoss()\n",
    "\n",
    "for ignore_kernel in [1]: # [0, 1]:\n",
    "    print('\\n\\n##NEW JOB')\n",
    "    print('ignore kernel', ignore_kernel)\n",
    "    print('# trials', data.shape[0])\n",
    "    model_by_k, res_next = mb.tl.optimize_iterative(train, device, w=w, show_logo=0, criterion=criterion,\n",
    "                                                 opt_kernel_shift=opt_kernel_shift, opt_kernel_length=opt_kernel_length,\n",
    "                                                 dirichlet_regularization=dirichlet_regularization, # 10 ** dirichlet_regularization_log,\n",
    "                                                 lr=lr, weight_decay=wd, ignore_kernel=ignore_kernel, use_mono=True,\n",
    "                                                 num_epochs=n_epochs, early_stopping=early_stopping, use_dinuc=True, # optimiser=torch.optim.LBFGS,\n",
    "                                                 n_kernels=n_kernels, log_each=log_each, stop_at_kernel=None) #  seed=seed) # seeds.index[0]) #\n",
    "    print('##DONE....\\n\\n')\n",
    "\n",
    "\n",
    "\n",
    "print('total time: %.3f s' % ((time.time() - t0)))\n",
    "# res = []\n",
    "# model_by_k = {}\n",
    "\n",
    "model = model_by_k\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### We can visualize the overall results obtained by the network, once the training is finished"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import mubind as mb"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = model_by_k\n",
    "mb.tl.scores(model, train)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 6, 6\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "counts = mb.tl.predict(model, train)\n",
    "counts"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 6, 6\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mb.pl.kmer_enrichment(model, train, log_scale=False, style='scatter', ylab='t1', xlab='p1')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mb.pl.conv(model)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import mubind as mb"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = model_by_k\n",
    "mb.tl.scores(model, train)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "counts = mb.tl.predict(model, train)\n",
    "counts"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 6, 6"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train.dataset.rounds.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = model_by_k\n",
    "mb.tl.scores(model, train)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "counts = mb.tl.predict(model, train)\n",
    "counts"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mb.pl.kmer_enrichment(model, train, log_scale=False, style='scatter', ylab='t1', xlab='p1')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mb.pl.conv_mono(model)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3c3d59-4088-4033-98a5-ed452c8c6d38",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import mubind as mb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import bindome as bd\n",
    "bd.constants.ANNOTATIONS_DIRECTORY = '../../annotations'\n",
    "# mb.models.MultiBind\n",
    "import torch.optim as topti\n",
    "import torch.utils.data as tdata\n",
    "import matplotlib.pyplot as plt\n",
    "import logomaker\n",
    "\n",
    "# Use a GPU if available, as it should be faster.\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device: \" + str(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def _mismatch(word, letters, num_mismatches):\n",
    "    for locs in itertools.combinations(range(len(word)), num_mismatches):\n",
    "        this_word = [[char] for char in word]\n",
    "        for loc in locs:\n",
    "            orig_char = word[loc]\n",
    "            this_word[loc] = [l for l in letters if l != orig_char]\n",
    "        for poss in itertools.product(*this_word):\n",
    "            yield \"\".join(poss)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# motif = \"ATT\"\n",
    "# x2, y2 = mb.datasets.simulate_xy(motif, n_trials=2100, seqlen=len(motif) + 1, max_mismatches=min(len(motif), 2), counts_size=1)\n",
    "# x2, y2\n",
    "# df = pd.DataFrame(data=y2)\n",
    "# df.columns = [1]\n",
    "# df.index = x2\n",
    "# df[0] = 0\n",
    "# df = df[[0, 1]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8b3b18-1b3d-49c8-8252-320bb1b971c5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = mb.bindome.datasets.ProBound.ctcf(flank_length=0)\n",
    "df = df.sort_values(1, ascending=False).reset_index(drop=True)\n",
    "# data = df.head(1000)\n",
    "# data = df.copy()\n",
    "data = df.sample(10000, random_state=50)\n",
    "# data = df.sample(df.shape[0], random_state=50)\n",
    "# data = df.copy()\n",
    "data.index = data['seq']\n",
    "\n",
    "# remove as many nucleotides as posisble (faster training/convergence)\n",
    "data.index = data.index.astype(str).str[45:]\n",
    "\n",
    "\n",
    "# data.index = data.index.astype(str).str[-15:]\n",
    "del data['seq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbc2e5d-53f4-4ef2-8141-be4063dca629",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = data.sample(data.shape[0], random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data.shape[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # define batches\n",
    "# batch = np.random.randint(2, size=data.shape[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # data[batch == 0] = data[batch == 0] + 20\n",
    "# # data[batch == 1] = data[batch == 1] + 10\n",
    "# data['batch'] = batch\n",
    "#\n",
    "# data = data[data['batch'] == 1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7feab1b-1726-4d88-b57a-060b6c8b6323",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from matplotlib import rcParams\n",
    "rcParams['figure.figsize'] = 5, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0301f36d-c2fd-4b03-9c12-e06b7c6c1db7",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: skipped for now\n",
    "n_rounds = 2\n",
    "\n",
    "print('loading object (# entries)', data.shape[0])\n",
    "dataset = mb.datasets.SelexDataset(data, n_rounds=n_rounds, labels=[0, 1])\n",
    "train = tdata.DataLoader(dataset=dataset,\n",
    "                         # batch_size=256,\n",
    "                         batch_size=512,\n",
    "                         shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1620ebe-cbb2-4bc8-a0f6-bfd60b3f117a",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c04087-128d-4680-8b0e-c3f488fa7654",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%load_ext line_profiler\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# %lprun -f mb.tl.train_network mb.tl.train_network(model, train, device, next_optimiser, criterion, num_epochs=20, early_stopping=100, log_each=2, dirichlet_regularization=0, exp_max=40, verbose=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# %lprun -f mb.tl.train_iterative mb.tl.train_iterative(train, device, w=18, show_logo=False, opt_kernel_shift=0, opt_kernel_length=0, dirichlet_regularization=dirichlet_regularization, lr=[0.01, 0.01], weight_decay=[0.01, 0.001], ignore_kernel=ignore_kernel, num_epochs=2, early_stopping=100, use_dinuc=False, n_kernels=n_kernels, log_each=log_each, stop_at_kernel=None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7475742f-41cd-4c70-bab5-eea4985f2cfa",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# assign batch and data type\n",
    "\n",
    "# data['batch'] = 0\n",
    "# data['is_count_data'] = 1\n",
    "# n_batches=3\n",
    "\n",
    "dirichlet_regularization = 0\n",
    "# for dirichlet_regularization_log in range(-5, 3):\n",
    "\n",
    "n_epochs = 100\n",
    "log_each = 10\n",
    "n_kernels = 4\n",
    "lr = [0.01] * n_kernels\n",
    "wd = [0.01,] + [0.001] * (n_kernels - 1)\n",
    "early_stopping = [5,] + [25] * (n_kernels - 1)\n",
    "w = 15 # min(len(motif), 6)\n",
    "opt_kernel_shift = 1\n",
    "opt_kernel_length = 1\n",
    "\n",
    "from matplotlib import rcParams\n",
    "rcParams['figure.figsize'] = 8, 1\n",
    "\n",
    "import time\n",
    "t0 = time.time()\n",
    "\n",
    "criterion = mb.tl.PoissonLoss()\n",
    "\n",
    "for ignore_kernel in [1]: # [0, 1]:\n",
    "    print('\\n\\n##NEW JOB')\n",
    "    print('ignore kernel', ignore_kernel)\n",
    "    model_by_k, res_next = mb.tl.optimize_iterative(train, device, w=w, show_logo=0, criterion=criterion,\n",
    "                                                 opt_kernel_shift=opt_kernel_shift, opt_kernel_length=opt_kernel_length,\n",
    "                                                 dirichlet_regularization=dirichlet_regularization, # 10 ** dirichlet_regularization_log,\n",
    "                                                 lr=wd, weight_decay=wd, ignore_kernel=ignore_kernel, use_mono=True,\n",
    "                                                 num_epochs=n_epochs, early_stopping=early_stopping, use_dinuc=True, # optimiser=torch.optim.LBFGS,\n",
    "                                                 n_kernels=n_kernels, log_each=log_each, stop_at_kernel=None) #  seed=seed) # seeds.index[0]) #\n",
    "    print('##DONE....\\n\\n')\n",
    "\n",
    "\n",
    "print('total time: %.3f s' % ((time.time() - t0)))\n",
    "# res = []\n",
    "# model_by_k = {}\n",
    "\n",
    "model = model_by_k\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbd5c33-a070-43f4-bc65-d51aa2b4cc02",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### We can visualize the overall results obtained by the network, once the training is finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import mubind as mb"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = model_by_k\n",
    "mb.tl.scores(model, train)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "counts = mb.tl.predict(model, train)\n",
    "counts"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 6, 6"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train.dataset.rounds.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mb.pl.kmer_enrichment(model, train, log_scale=False, style='scatter', ylab='t1', xlab='p1', k=9)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mb.pl.conv(model)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "mubind",
   "language": "python",
   "display_name": "mubind"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "21beeb3f351c8e886a898db8b4cccf8d4f8a70210033cb08b23469d9f8df079c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}